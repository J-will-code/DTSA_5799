{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["\n","# Special Install of Packages with clearer checks and updates\n","print('[-] Importing packages...')\n","\n","import os\n","import sys\n","\n","# Installing or checking for tmtoolkit and dependencies\n","try:\n","    import tmtoolkit\n","except ImportError:\n","    print('Installing tmtoolkit...')\n","    !pip install --quiet -U \"tmtoolkit[recommended,lda,sklearn,wordclouds,textproc_extra,topic_modeling_eval_extra]\"\n","    print('tmtoolkit installed.')\n","\n","# Installing or checking for matplotlib version\n","import matplotlib\n","if matplotlib.__version__ != \"3.1.3\":\n","    print('Installing specific matplotlib version (3.1.3)...')\n","    !pip uninstall --quiet -y matplotlib\n","    !pip install --quiet matplotlib==3.1.3\n","    print('matplotlib (3.1.3) installed.')\n","\n","# Installing lda library\n","try:\n","    from lda import LDA\n","except ImportError:\n","    print('Installing lda package...')\n","    !pip install --quiet lda\n","    print('lda installed.')\n","\n","# Check available RAM and GPU (if applicable)\n","print(\"\\n[INFO] Checking system resources...\")\n","\n","# Checking available RAM\n","from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print(f\"  [.] Your runtime has {ram_gb:.1f} GB of available RAM\")\n","if ram_gb < 16:\n","    print(\"  [.] Warning: This runtime may not be suitable for large datasets.\")\n","elif ram_gb >= 32:\n","    print(\"  [.] High-RAM runtime detected. Optimal for larger datasets.\")\n","\n","# Check GPU status (optional, can be removed)\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if 'failed' in gpu_info.lower():\n","    print(\"  [.] No GPU available.\")\n","else:\n","    print(f\"  [.] GPU found: {gpu_info.splitlines()[1]}\")\n"]},{"cell_type":"markdown","metadata":{"id":"lY1sN4KoCifk"},"source":["\n","# Section 1: Data Loading\n","import pandas as pd\n","\n","def load_data(filepath):\n","    '''\n","    Loads dataset from a given file path. Assumes the dataset contains a column named \"reviews\".\n","    Returns a Pandas DataFrame.\n","    '''\n","    try:\n","        df = pd.read_json(filepath)\n","        print(f\"Data loaded successfully with {df.shape[0]} rows and {df.shape[1]} columns.\")\n","        return df\n","    except Exception as e:\n","        print(f\"Error loading data: {e}\")\n","        return None\n","\n","# Example usage\n","data_path = 'path_to_your_data.json'\n","df = load_data(data_path)\n"]},{"cell_type":"markdown","metadata":{"id":"Vm8H3NhtDkZD"},"source":["\n","# Section 2: Text Preprocessing\n","import re\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","\n","# Download required NLTK resources\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","# Initialize stopwords and lemmatizer\n","stop_words = set(stopwords.words('english'))\n","lemmatizer = WordNetLemmatizer()\n","\n","def preprocess_text(text):\n","    '''\n","    Cleans and tokenizes input text.\n","    Steps include lowercasing, removing non-alphabetical characters, tokenizing, and lemmatizing.\n","    '''\n","    text = text.lower()\n","    text = re.sub(r'[^a-z\\s]', '', text)  # Remove non-alphabetical characters\n","    tokens = text.split()\n","    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n","    return ' '.join(tokens)\n","\n","# Apply preprocessing to the review column\n","df['cleaned_text'] = df['reviews'].apply(preprocess_text)\n","print(\"Text preprocessing completed.\")\n"]},{"cell_type":"markdown","metadata":{"id":"i3KqgfWeViZu"},"source":["\n","# Section 3: LDA Topic Modeling\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.decomposition import LatentDirichletAllocation\n","from sklearn.model_selection import train_test_split\n","\n","# Vectorize the cleaned text\n","vectorizer = CountVectorizer(max_df=0.9, min_df=5, stop_words='english')\n","X = vectorizer.fit_transform(df['cleaned_text'])\n","\n","# Split data for train and evaluation\n","X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n","\n","# Train the LDA model\n","def train_lda_model(X, n_topics=10, max_iter=10, random_state=42):\n","    '''\n","    Trains an LDA model and returns the trained model.\n","    '''\n","    lda = LatentDirichletAllocation(n_components=n_topics, max_iter=max_iter, random_state=random_state)\n","    lda.fit(X)\n","    return lda\n","\n","lda_model = train_lda_model(X_train, n_topics=10)\n","print(\"LDA model training completed.\")\n","\n","# Step 4: Evaluating the Model\n","def evaluate_lda_model(lda_model, X_test):\n","    '''\n","    Evaluates the LDA model using log-likelihood and perplexity.\n","    '''\n","    log_likelihood = lda_model.score(X_test)\n","    perplexity = lda_model.perplexity(X_test)\n","    print(f\"Log-Likelihood: {log_likelihood}, Perplexity: {perplexity}\")\n","\n","evaluate_lda_model(lda_model, X_test)\n"]},{"cell_type":"markdown","metadata":{"id":"Rc9iJV4NDkj6"},"source":["\n","# Section 4: Visualizing Topics\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from wordcloud import WordCloud\n","\n","def display_topics(model, feature_names, n_top_words=10):\n","    '''\n","    Displays the top words for each topic in both text and visual word cloud formats.\n","    '''\n","    for topic_idx, topic in enumerate(model.components_):\n","        print(f\"Topic {topic_idx}:\")\n","        print(\"Top words: \", [feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]])\n","        \n","        # Generate word cloud\n","        wordcloud = WordCloud()\n","        plt.figure()\n","        plt.imshow(wordcloud.fit_words({feature_names[i]: topic[i] for i in topic.argsort()[:-n_top_words - 1:-1]}))\n","        plt.axis(\"off\")\n","        plt.title(f\"Topic {topic_idx} WordCloud\")\n","        plt.show()\n","\n","# Get feature names from vectorizer\n","feature_names = vectorizer.get_feature_names_out()\n","display_topics(lda_model, feature_names)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6YRoOyQDwdHV","outputId":"ae56bbb0-cb12-498a-d827-01c4ccf69301"},"outputs":[{"output_type":"stream","name":"stdout","text":["[-] Importing packages...\n","starting patch of matplotlib.\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for matplotlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","arviz 0.19.0 requires matplotlib>=3.5, but you have matplotlib 3.1.3 which is incompatible.\n","bigframes 1.21.0 requires matplotlib>=3.7.1, but you have matplotlib 3.1.3 which is incompatible.\n","plotnine 0.13.6 requires matplotlib>=3.7.0, but you have matplotlib 3.1.3 which is incompatible.\n","seaborn 0.13.2 requires matplotlib!=3.6.1,>=3.4, but you have matplotlib 3.1.3 which is incompatible.\n","tmtoolkit 0.12.0 requires matplotlib<4.0,>=3.5.0, but you have matplotlib 3.1.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["# Special Install of Packages\n","print('[-] Importing packages...')\n","#special_install_tmtoolkit\n","import os\n","try:\n","  import tmtoolkit\n","except:\n","  print('starting patch of tmtoolkit.')\n","  !pip install --quiet -U \"tmtoolkit[recommended,lda,sklearn,wordclouds,textproc_extra,topic_modeling_eval_extra]\"\n","  print('finished patch of tmtoolkit.')\n","  os.kill(os.getpid(), 9)\n","\n","#special_install_matplotlib\n","import os\n","import matplotlib\n","if matplotlib.__version__ != \"3.1.3\":\n","    print('starting patch of matplotlib.')\n","    !pip uninstall --quiet -y matplotlib\n","    !pip install --quiet matplotlib==3.1.3\n","    print('finished patch of matplotlib.')\n","    os.kill(os.getpid(), 9)\n","\n","#special_install_lda\n","import os\n","try:\n","  from tmtoolkit.topicmod.tm_lda import compute_models_parallel\n","except:\n","  !pip install --quiet tmtoolkit['lda']\n","  from tmtoolkit.topicmod.tm_lda import compute_models_parallel\n","\n","try:\n","  from lda import LDA\n","except:\n","  !pip install --quiet lda\n","  from lda import LDA\n","\n","#special_install_pyLDAvis\n","try:\n","  import pyLDAvis\n","except:\n","  !pip install --quiet pyLDAvis==2.1.2\n","  import pyLDAvis\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H380lVJDDpRT"},"outputs":[],"source":["print('[-] Importing packages...')\n","# File Connection and File Manipulation\n","import os\n","import pickle\n","import json\n","import glob\n","# Import Usability Functions\n","import logging\n","import warnings\n","# Basic Data Science Toolkits\n","import pandas as pd\n","import numpy as np\n","import math\n","import random\n","import time\n","from time import sleep\n","# Basic Data Vizualization\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","# Text Preprocessing (tmtoolkit)\n","import tmtoolkit\n","from tmtoolkit.corpus import Corpus, lemmatize, to_lowercase, remove_chars, filter_clean_tokens\n","from tmtoolkit.corpus import filter_for_pos, remove_common_tokens, remove_uncommon_tokens\n","from tmtoolkit.corpus import corpus_num_tokens, corpus_tokens_flattened\n","from tmtoolkit.corpus import doc_tokens, tokens_table, doc_labels, dtm\n","from tmtoolkit.corpus import vocabulary, vocabulary_size, vocabulary_counts\n","from tmtoolkit.topicmod.model_io import print_ldamodel_topic_words\n","from tmtoolkit.topicmod.tm_lda import compute_models_parallel\n","from tmtoolkit.corpus.visualize import plot_doc_lengths_hist, plot_doc_frequencies_hist, plot_ranked_vocab_counts\n","#https://tmtoolkit.readthedocs.io/en/latest/preprocessing.html\n","# Text Preprocessing(other)\n","from string import punctuation\n","import nltk\n","import scipy.sparse\n","# Topic Modeling\n","from lda import LDA\n","import pyLDAvis\n","from tmtoolkit.topicmod import tm_lda\n","from tmtoolkit.topicmod.tm_lda import compute_models_parallel\n","from tmtoolkit.topicmod.model_io import print_ldamodel_topic_words\n","from tmtoolkit.topicmod.model_io import save_ldamodel_to_pickle\n","from tmtoolkit.topicmod.model_io import load_ldamodel_from_pickle\n","from tmtoolkit.topicmod.model_io import ldamodel_top_doc_topics\n","from tmtoolkit.topicmod.evaluate import results_by_parameter\n","from tmtoolkit.topicmod.visualize import plot_eval_results\n","from tmtoolkit.topicmod.visualize import parameters_for_ldavis\n","from tmtoolkit.topicmod.visualize import generate_wordclouds_for_topic_words\n","from tmtoolkit.topicmod.model_stats import generate_topic_labels_from_top_words\n","from tmtoolkit.bow.bow_stats import doc_lengths\n","# Sentiment Modeling\n","from textblob import TextBlob\n","# normalize\n","from sklearn.preprocessing import MinMaxScaler"]},{"cell_type":"markdown","metadata":{"id":"gkSK-tf_w07v"},"source":["## Set Global Variables"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VAB5u0jbw1Et"},"outputs":[],"source":["random.seed(20191120)   # to make the sampling reproducible\n","np.set_printoptions(precision=5)"]},{"cell_type":"markdown","metadata":{"id":"trDcYLfsDkpX"},"source":["## Verify GPU Runtime"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s7yTkyWkDt9R"},"outputs":[],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O-WqHeL7Dxyp"},"outputs":[],"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('  [.] Your runtime has {:.1f} gigabytes of available RAM'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('  [.] Not using a high-RAM runtime')\n","else:\n","  print('  [.] You are using a high-RAM runtime!')"]},{"cell_type":"markdown","metadata":{"id":"I-dych_HDktc"},"source":["## Mount Google Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hsxT8HBSD1TA"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"ux9ssn7tDkwc"},"source":["## Setup Directories"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QgUhHdlkD4_h"},"outputs":[],"source":["ROOT_DIR = \"/content/drive/MyDrive/MSDS_marketing_text_analytics/master_files/2_topic_modeling\"\n","DATA_DIR = \"%s/data\" % ROOT_DIR\n","EVAL_DIR = \"%s/evaluation\" % ROOT_DIR\n","MODEL_DIR = \"%s/models\" % ROOT_DIR\n","\n","#Create missing directories, if they don't exist\n","if not os.path.exists(DATA_DIR):\n","  # Create a new directory because it does not exist\n","  os.makedirs(DATA_DIR)\n","  print(\"The data directory is created!\")\n","if not os.path.exists(EVAL_DIR):\n","  # Create a new directory because it does not exist\n","  os.makedirs(EVAL_DIR)\n","  print(\"The evaluation directory is created!\")\n","if not os.path.exists(MODEL_DIR):\n","  # Create a new directory because it does not exist\n","  os.makedirs(MODEL_DIR)\n","  print(\"The model directory is created!\")"]},{"cell_type":"markdown","metadata":{"id":"uaL-mWljDkzE"},"source":["# 2.&nbsp;Data Source\n","\n","Import the product and review data and focus the datasets on the Nike brand. This is accomplished by identifing the ASINs associated with products related to the Nike brand using the product dataset. Using a list of the products, the reviews can be filtered with the list of ASINs, resulting in a subset of review data associated to the Nike brand."]},{"cell_type":"markdown","metadata":{"id":"GwCxNYFLD_mO"},"source":["## Copy Data From Source"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qF0u3FMYFN2l"},"outputs":[],"source":["#!wget <URL> -P <COLAB PATH>\n","#source_url = 'http://128.138.93.164/meta_Clothing_Shoes_and_Jewelry.json.gz' # true source, need better link\n","source_url = 'https://docs.google.com/uc?export=download&id=12cPbdNpQ6Dmqg25Fb0kAxFSEug-8t3gc&confirm=t' # local source, working for testing\n","dest_path = '%s/meta_Clothing_Shoes_and_Jewelry.jsonl.gz' % DATA_DIR\n","!wget \"$source_url\" -O \"$dest_path\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UiXBplpkFN-Z"},"outputs":[],"source":["#!wget <URL> -P <COLAB PATH>\n","#source_url = 'http://128.138.93.164/reviews_Clothing_Shoes_and_Jewelry.json.gz' # true source, need better link\n","source_url = \"https://docs.google.com/uc?export=download&id=12detwlesuD7S-O8i9w4LOii1DWML0i7Q&confirm=t\" # local source, working for testing\n","dest_path = '%s/reviews_Clothing_Shoes_and_Jewelry.json.gz' % DATA_DIR\n","file_name = 'reviews_Clothing_Shoes_and_Jewelry.json.gz'\n","print(dest_path)\n","!wget \"$source_url\" -O \"$dest_path\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RE5Bt8SpGJuJ"},"outputs":[],"source":["meta_file_path = '%s/meta_Clothing_Shoes_and_Jewelry.jsonl.gz' % DATA_DIR\n","review_file_path = '%s/reviews_Clothing_Shoes_and_Jewelry.json.gz' % DATA_DIR\n","\n","!gzip -d \"$meta_file_path\"\n","!gzip -d \"$review_file_path\""]},{"cell_type":"markdown","metadata":{"id":"iLawHwl8Dk3H"},"source":["## Load the Product Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XpLJWRlyG66-"},"outputs":[],"source":["##this assigns the filename we're trying to load in to a string variable\n","meta_file_path = '%s/meta_Clothing_Shoes_and_Jewelry.jsonl' % DATA_DIR\n","loadedjson = open(meta_file_path, 'r')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JgonsDHsHiGy"},"outputs":[],"source":["#The data used in this script comes from: http://jmcauley.ucsd.edu/data/amazon/links.html\n","#The data here is the 'per category' data for Clothing, Shoes and Jewelry\n","#use the above url to better understand the data, where it came from, and some\n","#tips on how to use it!\n","\n","#getting reviews is going to be a two step process:\n","#1) go through the amazon product catalog for \"Clothing, Shoes and Jewelery\n","#and extract out matching products by their ASIN\n","#2) go through the review data and parse out the matching reviews by ASIN\n","\n","#1) - Extracting ASINs by brand\n","#First, let's iterate through the data and store it as a python dictionary\n","\n","#let's set a counter to see how many products we have in the json\n","count = 0\n","start_time = time.time()\n","#loading the json file\n","#we've always got to initiate dictionaries before we can use them\n","allproducts = {}\n","\n","#each line of data here is a product and its metadata\n","print('loading product data to dictionary:')\n","for aline in loadedjson:\n","    #creating a counter to know our progress in processing the entire catalog\n","    count += 1\n","    if count % 100000 == 0:\n","        #we're only going to print our count every 100k, this way we don't spam\n","        #our output console\n","        current_runtime = round(time.time() - start_time,3)\n","        print('[-] current progress:', count, 'and a runtime of', current_runtime, 'seconds.')\n","    #interestingly enough, this data isn't true JSON, instead it's python\n","    #dictionaries that have essentially been printed as text. It's odd, but if\n","    #we read the documentaion, all we need to do to load a dictionary is use\n","    #the eval function. https://www.programiz.com/python-programming/methods/built-in/eval\n","    #eval takes whatever string is passed to it, and interprets it as python code\n","    #and runs it. So here, it's exactly what we need to interpret a printed\n","    #python dictionary\n","\n","    aproduct = eval(aline)\n","\n","    #making a dictionary entry with the ASIN of the product as the key\n","    #and it's metadata as nested dictionaries\n","    allproducts[aproduct['asin']] = aproduct"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"82nO1J0qK7px"},"outputs":[],"source":["#print a summary of the records processed\n","allproducts_length = len(allproducts)\n","current_runtime = round(time.time() - start_time,3)\n","print('Process completed for', count, 'of', allproducts_length, 'records with a final runtime of', current_runtime, 'seconds.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NLbsplxmQbXw"},"outputs":[],"source":["#preview the product record\n","allproducts['B00KUSKHDC']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wnLx_wqbO--o"},"outputs":[],"source":["#save the files to disk\n","allproducts_file_path = '%s/allproducts.p' % DATA_DIR\n","pickle.dump(allproducts, open(allproducts_file_path, 'wb'))"]},{"cell_type":"markdown","metadata":{"id":"SM_uvP__Xj3q"},"source":["## Summarize the Product Categories"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z8HacV-QLvxB"},"outputs":[],"source":["#Next we need to explore the product data to see what categories are common in the\n","#data. As you'll learn, product categories are wishywashy in that they can be\n","#product categories (e.g., baby, house and home), or they can be brands!\n","#We're already dealing with a subset of the product categories, Clothing, Shoes\n","#and Jewlery. We still need to find a list of product ids for our specific\n","#brand. To do this,We're going to use the 'categories' metadata field to find\n","#your brand\n","\n","##Let's create a dictionary of all the product subcategories\n","#and by doing so, also come up with a list of brands and the number of products\n","#they have listed in the amazon product catalog\n","\n","allcategories = {}\n","count = 0\n","start_time = time.time()\n","\n","#each line of data here is a product and its metadata\n","print('loading categories data to dictionary:')\n","for aproduct in allproducts:\n","    #creating a counter to know our progress in processing the entire catalog\n","    count += 1\n","    if count % 100000 == 0:\n","        #we now know there are 1.5 million products, so we can build a counter\n","        #that tells how our processing is going. When the counter reaches one\n","        #we're done!\n","        current_progress = int(round(count/allproducts_length,2)*100)\n","        current_runtime = round(time.time() - start_time,3)\n","        print('[-] current progress:', current_progress, '%', 'and a runtime of', current_runtime, 'seconds.')\n","\n","    #setting a dict up with just one product, so we can inspect and ref it\n","    aproduct = allproducts[aproduct]\n","    #creating a dictionary entry for each product category\n","    #also counting the occurances of each category\n","    if 'categories' in aproduct:\n","        for categories in aproduct['categories']:\n","            for acategory in categories:\n","                if acategory in allcategories:\n","                    allcategories[acategory] += 1\n","                if acategory not in allcategories:\n","                    allcategories[acategory] = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DYX33syoMams"},"outputs":[],"source":["#print a summary of the categories processed\n","allcategories_length = len(allcategories)\n","current_runtime = round(time.time() - start_time,3)\n","print('Process completed for', allcategories_length, 'categories with a final runtime of', current_runtime, 'seconds.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"24HHwOM3MvMp"},"outputs":[],"source":["#create a sorted list of categories\n","sortedlist = []\n","#covert the dictionary to a list of tuples\n","for acategory in allcategories:\n","  sortedlist.append((allcategories[acategory],acategory))\n","#sort the list\n","sortedlist = sorted(sortedlist, reverse=True)\n","#print the top x records in the list\n","top_n = 20\n","for item in range(0,top_n):\n","  print('[',str(item).zfill(2),']', sortedlist[item])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pphGYYnnNJ0B"},"outputs":[],"source":["nike_categories = allcategories['Nike']\n","print(nike_categories, 'product records for Nike.')"]},{"cell_type":"markdown","metadata":{"id":"9_8Wzo6RXpvC"},"source":["## Extract a List of Product Ids"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lMutjGO2NxCI"},"outputs":[],"source":["#Now, go ahead and use the Variable Expolorer in Spyder to locate a brand\n","#that has a lot of product entries! Alternatively, type allcategories['Brand name']\n","#to get a count for a specific brand. For instance:\n","#>>allcategories['Nike']\n","#>> 8327\n","#>>allcategories['adidas']\n","#>> 8645\n","\n","#I'd reccommend at least 1.5k products, but you're welcome to try smaller counts\n","#all I care about is whether you have at least 2k reviews when it's all said and done\n","\n","\n","##Now we need to go through our newly first dictionary and extract out the\n","##matching ASINs for Nike\n","\n","##First, create a set where we will store our ASINs\n","##We choose a set here because we don't want duplicates\n","allnikeasins = set()\n","count = 0\n","start_time = time.time()\n","\n","for areview in allproducts:\n","    theproduct = allproducts[areview]\n","    count += 1\n","    if count % 100000 == 0:\n","        current_progress = int(round(count/allproducts_length,2)*100)\n","        current_runtime = round(time.time() - start_time,3)\n","        print('[-] current progress:', current_progress, '%', 'and a runtime of', current_runtime, 'seconds.')\n","\n","    #let's iterate fore each category for a product, again, any given product\n","    #can be assigned multiple product categories,\n","    for categories in theproduct['categories']:\n","        #each category is actually encoded as a list (even though they should\n","        #just be strings, so we need to iterate one more time)\n","        for acategory in categories:\n","            #checking to see if the product category matches Nike\n","            #lowercasing the category string incase capitalization might get\n","            #in the way of a match\n","            if 'nike' in acategory.lower():\n","                #let's go ahead and store it to our set of Nike ASINs\n","                allnikeasins.add(theproduct['asin'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QJnKh-pJN31B"},"outputs":[],"source":["#print a summary of the categories processed\n","allnikeasins_length = len(allnikeasins)\n","current_runtime = round(time.time() - start_time,3)\n","print('Process completed for', allnikeasins_length, 'records with a final runtime of', current_runtime, 'seconds.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3w3CxJ7AOSrF"},"outputs":[],"source":["# write the ASINs out to a file as a checkpoint\n","outputfile = open('%s/allasins.txt' % DATA_DIR, 'w')\n","\n","outputfile.write(','.join(allnikeasins))\n","outputfile.close()"]},{"cell_type":"markdown","metadata":{"id":"FoMzFNfNqYXS"},"source":["## Load the Review Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JTQOhtdOqYiL"},"outputs":[],"source":["#this assigns the filename we're trying to load in to a string variable\n","review_file_path = '%s/reviews_Clothing_Shoes_and_Jewelry.json' % DATA_DIR\n","loadedjson = open(review_file_path, 'r')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sBxD7Mz9qYqt"},"outputs":[],"source":["#2) - Parsing the review data\n","#First, let's iterate through the data and store it as a python dictionary\n","\n","#let's set a counter to see how many products we have in the json\n","count = 0\n","start_time = time.time()\n","#loading the json file\n","#we've always got to initiate dictionaries before we can use them\n","allreviews = {}\n","\n","#each line of data here is a product and its metadata\n","print('loading review data to dictionary:')\n","for aline in loadedjson:\n","    #creating a counter to know our progress in processing the entire catalog\n","    count += 1\n","    if count % 500000 == 0:\n","        #we're only going to print our count every 100k, this way we don't spam\n","        #our output console\n","        current_runtime = round(time.time() - start_time,3)\n","        print('[-] current progress:', count, 'and a runtime of', current_runtime, 'seconds.')\n","    #interestingly enough, this data isn't true JSON, instead it's python\n","    #dictionaries that have essentially been printed as text. It's odd, but if\n","    #we read the documentaion, all we need to do to load a dictionary is use\n","    #the eval function. https://www.programiz.com/python-programming/methods/built-in/eval\n","    #eval takes whatever string is passed to it, and interprets it as python code\n","    #and runs it. So here, it's exactly what we need to interpret a printed\n","    #python dictionary\n","\n","    areview = eval(aline)\n","\n","    #making a dictionary entry with the iteration count as the review key\n","    #and it's metadata as nested dictionaries\n","    allreviews[count] = areview\n","print('completed load of review data to dictionary.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PBwc5FH0qYwm"},"outputs":[],"source":["#print a summary of the records processed\n","allreviews_length = len(allreviews)\n","current_runtime = round(time.time() - start_time,3)\n","print('Process completed for', count, 'of', allreviews_length, 'records with a final runtime of', current_runtime, 'seconds.')"]},{"cell_type":"markdown","metadata":{"id":"W4mwdMoVrvRc"},"source":["## Extract a List of Reviews Related to the Product Ids"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G342m_ScrvZo"},"outputs":[],"source":["#Load the list of Nike Asins\n","\n","allnikeasins = []\n","allasins_file_path = '%s/allasins.txt' % DATA_DIR\n","\n","#open the file and load to a list\n","for data in open(allasins_file_path, 'r'):\n","  asins = data.split(',')\n","  for anasin in asins:\n","    allnikeasins.append(anasin)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LH-GwtrytizW"},"outputs":[],"source":["#print a summary of the records processed\n","allnikeasins_length = len(allnikeasins)\n","print('Process completed for', allnikeasins_length, 'records.')\n","print('First 5 Asins in list:', allnikeasins[0:5])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b-fX3DsWso5E"},"outputs":[],"source":["#Now, we need to go through all the reviews and pick out the reviews that\n","#correspond to the matching ASINs, that is reviews that are tied to Nike ASINs\n","\n","#let's set a counter to see how many products we have in the json\n","count = 0\n","start_time = time.time()\n","#loading the json file\n","#we've always got to initiate dictionaries before we can use them\n","nikereviews = {}\n","\n","#each line of data here is a product and its metadata\n","print('loading review data to dictionary:')\n","for areview in allreviews:\n","  count += 1\n","  if count % 500000 == 0:\n","      current_progress = int(round(count/allreviews_length,2)*100)\n","      current_runtime = round(time.time() - start_time,3)\n","      print('[-] current progress:', current_progress, '%', 'and a runtime of', current_runtime, 'seconds.')\n","  #setting current review as a dictionary, so we can easily reference its\n","  #entries\n","  thereview = allreviews[areview]\n","  theasin = thereview['asin']\n","  reviewerid = thereview['reviewerID']\n","  if theasin in allnikeasins:\n","      #im setting the key here as something unique. if we just did by asin\n","      #we'd only have one review for each asin, with the last review the only\n","      #one being stored\n","      thekey = '%s.%s' % (theasin, reviewerid)\n","      nikereviews[thekey] = thereview\n","print('completed load of review data to dictionary.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PId1RbyvsMaO"},"outputs":[],"source":["#print a summary of the records processed\n","nikereviews_length = len(nikereviews)\n","current_runtime = round(time.time() - start_time,3)\n","print('Process completed for', count, 'of', nikereviews_length, 'records with a final runtime of', current_runtime, 'seconds.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4FBY0qHUtBtH"},"outputs":[],"source":["#save our data to a JSON dictionary\n","allnikereviews_file_path = '%s/allnikereviews.json' % DATA_DIR\n","json.dump(nikereviews, open(allnikereviews_file_path, 'w'))"]},{"cell_type":"markdown","metadata":{"id":"idr8Itvsvc4z"},"source":["## Preview a Record from the File"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yFoB9nR6vdBb"},"outputs":[],"source":["#this assigns the filename we're trying to load\n","allnikereviews_file_path = '%s/allnikereviews.json' % DATA_DIR\n","json_file = json.load(open(allnikereviews_file_path, 'r'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lAJnHBS7vdFQ"},"outputs":[],"source":["#select a random review\n","count = 0\n","for a_review in json_file:\n","  count += 1\n","  if count % 1000 == 0:\n","    the_review = json_file[a_review]\n","    print(the_review)\n","    #sleep(10)\n","  if count >= 10000:\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ESPlq5dvvdJJ"},"outputs":[],"source":["#print the review to the screen\n","the_review"]},{"cell_type":"markdown","metadata":{"id":"zWr-KpXhPo9C"},"source":["## Extract a List of Products Related to Product Ids"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zQzPRfHaPpKN"},"outputs":[],"source":["#Load the list of Nike Asins\n","\n","allnikeasins = []\n","allasins_file_path = '%s/allasins.txt' % DATA_DIR\n","\n","#open the file and load to a list\n","for data in open(allasins_file_path, 'r'):\n","  asins = data.split(',')\n","  for anasin in asins:\n","    allnikeasins.append(anasin)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hSq6zk02P1ee"},"outputs":[],"source":["#print a summary of the records processed\n","allnikeasins_length = len(allnikeasins)\n","print('Process completed for', allnikeasins_length, 'records.')\n","print('First 5 Asins in list:', allnikeasins[0:5])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3UlJmaBtP41o"},"outputs":[],"source":["#the path for the all product dict\n","allproducts_file_path = '%s/allproducts.p' % DATA_DIR\n","#load the dict\n","allproducts =  pickle.load(open(allproducts_file_path, 'rb'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lt9tzZnSR0JZ"},"outputs":[],"source":["print('size of the full product catelog:', len(allproducts))\n","keys = set(allnikeasins).intersection(allproducts)\n","allnikeproducts = {key:allproducts[key] for key in keys}\n","print('size of the nike product catelog:', len(allnikeproducts))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7F8S1aNFS5nH"},"outputs":[],"source":["#save the files to disk\n","allnikeproducts_file_path = '%s/allnikeproducts.p' % DATA_DIR\n","pickle.dump(allnikeproducts, open(allnikeproducts_file_path, 'wb'))"]},{"cell_type":"markdown","metadata":{"id":"VQqWaZtyDk7D"},"source":["# 3.&nbsp;Preprocessing the Data"]},{"cell_type":"markdown","metadata":{"id":"qxanJVFlv_cQ"},"source":["## Load the Nike Review Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9FWNy7Fav_kD"},"outputs":[],"source":["#this assigns the filename we're trying to load\n","allnikereviews_file_path = '%s/allnikereviews.json' % DATA_DIR\n","json_file = json.load(open(allnikereviews_file_path, 'r'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"glFt6w9Fv_ny"},"outputs":[],"source":["#extract review text from all review details\n","reviews = []\n","for a_review in json_file:\n","    the_review = json_file[a_review]\n","    text = the_review[\"reviewText\"]\n","    reviews.append(text)"]},{"cell_type":"markdown","metadata":{"id":"SriQz-W0ppEs"},"source":["## Create the Corpus"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0BvxUkt_Nrtw"},"outputs":[],"source":["#create a corpus of the nike reviews\n","corpus = Corpus({ i:r for i, r in enumerate(reviews)}, language='en')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yRLd7_Cxv_qr"},"outputs":[],"source":["#print the length of the corpus\n","corpus_length = len(corpus)\n","print('Length of the Corpus:', corpus_length)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XbbBxEXIv_tq"},"outputs":[],"source":["#create a summary of the preprocess\n","n = 10\n","k = 91\n","vocab_size = vocabulary_size(corpus)\n","df_tokens = tmtoolkit.corpus.tokens_table(corpus)\n","#print a summary of the preprocess\n","print('record for key', k, 'contains:')\n","print(corpus[k])\n","print('corpus vocabulary size:', vocab_size)\n","print('first', n, 'rows of tokens table:')\n","print(df_tokens[df_tokens['doc'] == k])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VOQEVTwnymRC"},"outputs":[],"source":["#view a histogram of document lengths\n","fig, ax = plt.subplots(figsize=(5, 3))   # make the plot larger\n","plot_doc_lengths_hist(fig, ax, corpus, y_log=False, bins=20)  # use 20 bins\n","ax.set_xticks(range(0, 1001, 100))    # set x axis ticks and range\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YbZEU3IeKV2O"},"outputs":[],"source":["#rank-frequency distribution plot for token frequencies\n","fig, ax = plt.subplots(figsize=(5, 3))\n","plot_ranked_vocab_counts(fig, ax, corpus, zipf=True)\n","plt.show();"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gHs_P3cBvCXT"},"outputs":[],"source":["#save the files to disk\n","corpus_file_path = '%s/corpus_source.p' % DATA_DIR\n","pickle.dump(corpus, open(corpus_file_path, 'wb'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CDD6r0wMOFRp"},"outputs":[],"source":["#save the raw text of reviews to disk\n","text_file_path = '%s/corpus_raw_text.p' % DATA_DIR\n","pickle.dump(reviews, open(text_file_path, 'wb'))"]},{"cell_type":"markdown","metadata":{"id":"rfAX7oZkywiN"},"source":["## Preprocess Text Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m0mW4aqvvS02"},"outputs":[],"source":["#location of corpus files\n","corpus_file_path = '%s/corpus_source.p' % DATA_DIR\n","#load the corpus\n","corpus = pickle.load(open(corpus_file_path, 'rb'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hTBI_xPXvqpX"},"outputs":[],"source":["#create a summary of the preprocess\n","n = 10\n","k = 91\n","vocab_size = vocabulary_size(corpus)\n","df_tokens = tmtoolkit.corpus.tokens_table(corpus)\n","#print a summary of the preprocess\n","print('record for key', k, 'contains:')\n","print(corpus[k])\n","print('corpus vocabulary size:', vocab_size)\n","print('first', n, 'rows of tokens table:')\n","print(df_tokens[df_tokens['doc'] == k])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6TGbhg9fywqr"},"outputs":[],"source":["####create an english pre-processor\n","####preproc = TMPreproc(corpus, language='en')\n","####tag the words with parts of speach\n","####preproc.pos_tag()\n","# lemmatize the words (convert to root base)\n","lemmatize(corpus, inplace=True)\n","# convert words to lowercase\n","to_lowercase(corpus, inplace=True)\n","# remove special charecters\n","#####preproc.remove_special_chars_in_tokens()\n","remove_chars(corpus, chars=punctuation, inplace=True)\n","# add custom stopwords to remove for urls and not\n","####preproc.add_stopwords(['http', 'nt'])       #####\n","filter_clean_tokens(corpus, remove_stopwords=True, inplace=True)\n","# limit words to nouns, verbs, and adjectives\n","filter_for_pos(corpus, search_pos=['N', 'V', 'ADJ'], inplace=True)\n","# remove numbers and any word shorter than 2 characters\n","filter_clean_tokens(corpus, remove_numbers=True, inplace=True)\n","filter_clean_tokens(corpus, remove_shorter_than=2, inplace=True)\n","# remove tokens that are fairly common\n","remove_common_tokens(corpus, df_threshold=0.90, inplace=True)\n","# remove tokens that are extreamly rare\n","remove_uncommon_tokens(corpus, df_threshold=0.01, inplace=True)"]},{"cell_type":"markdown","metadata":{"id":"HNZMaAvjzMR2"},"source":["## Review Preprocessing of Text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tILVppqtzMZa"},"outputs":[],"source":["#create a summary of a sample\n","def preview_sample_review(corpus, k = 0):\n","  samp_texty = corpus[k]\n","  tok = doc_tokens(corpus, with_attr=True)\n","  samp_token_list = tok[k]['token']\n","  samp_token_list_length = len(samp_token_list)\n","\n","  #print a random corpus\n","  print('record for key', k, 'contains:')\n","  print(corpus[k])\n","  print('the text contains', samp_token_list_length, 'tokens.')\n","  print('sample token list:', samp_token_list[0:10])\n","  print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mvge12yS1n15"},"outputs":[],"source":["#preview a couple specific lists of tokens in the corpus\n","preview_sample_review(corpus, k = 91)\n","preview_sample_review(corpus, k = 1)\n","preview_sample_review(corpus, k = 2000)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QV-I-zm1ywuw"},"outputs":[],"source":["#create a summary of the preprocess\n","n = 10\n","k = 91\n","vocab_size = vocabulary_size(corpus)\n","df_tokens = tmtoolkit.corpus.tokens_table(corpus)\n","#print a summary of the preprocess\n","print('record for key', k, 'contains:')\n","print(corpus[k])\n","print('corpus vocabulary size:', vocab_size)\n","print('first', n, 'rows of tokens table:')\n","print(df_tokens[df_tokens['doc'] == k])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bUht5wnfcq3D"},"outputs":[],"source":["#view a histogram of document lengths\n","fig, ax = plt.subplots(figsize=(5, 3))   # make the plot larger\n","plot_doc_lengths_hist(fig, ax, corpus, y_log=False, bins=50)  # use 20 bins\n","ax.set_xticks(range(0, 201, 20))    # set x axis ticks and range\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wRCcpYj7c2lY"},"outputs":[],"source":["#rank-frequency distribution plot for token frequencies\n","fig, ax = plt.subplots(figsize=(5, 3))\n","plot_ranked_vocab_counts(fig, ax, corpus, zipf=True)\n","plt.show();"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6GpodA8lmXzl"},"outputs":[],"source":["#summarize the size of the vocabulary\n","vocabulary_size(corpus)"]},{"cell_type":"markdown","metadata":{"id":"RHwH4bHT19pi"},"source":["## Save the Preprocessed Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xBj_8Hhh19xH"},"outputs":[],"source":["#create the document labels\n","doc_lbls = np.array(doc_labels(corpus))\n","#preview the document labels\n","print(doc_lbls[:10])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0PRw7x-aywyA"},"outputs":[],"source":["#create the vocabulary\n","vocab = np.array(vocabulary(corpus))\n","#preview the document labels\n","print(vocab[:10])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9xvoSJGK2TuM"},"outputs":[],"source":["#create the document-term matrix (DTM)\n","dtm_main = dtm(corpus)\n","#dtm_main = scipy.sparse.csr_matrix(dtm_main)\n","#preview the dtm\n","dtm_main"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wjF5mUY12tYy"},"outputs":[],"source":["#save the files to disk\n","corpus_file_path = '%s/corpus.p' % DATA_DIR\n","doc_labels_file_path = '%s/doc_labels.p' % DATA_DIR\n","vocab_file_path = '%s/vocab.p' % DATA_DIR\n","dtm_file_path = '%s/dtm_main.npz' % DATA_DIR\n","\n","pickle.dump(corpus, open(corpus_file_path, 'wb') )\n","pickle.dump(doc_lbls, open(doc_labels_file_path, 'wb'))\n","pickle.dump(vocab, open(vocab_file_path, 'wb'))\n","scipy.sparse.save_npz(dtm_file_path, dtm_main)"]},{"cell_type":"markdown","metadata":{"id":"ccZlhJcEEee5"},"source":["# 4.&nbsp;Model: Parameter Tuning"]},{"cell_type":"markdown","metadata":{"id":"QjMnhzHAh_DH"},"source":["## Import the Corpus"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GCwj-JqNh_LG"},"outputs":[],"source":["#location of corpus files\n","corpus_file_path = '%s/corpus.p' % DATA_DIR\n","doc_labels_file_path = '%s/doc_labels.p' % DATA_DIR\n","vocab_file_path = '%s/vocab.p' % DATA_DIR\n","dtm_file_path = '%s/dtm_main.npz' % DATA_DIR\n","\n","#load the corpus\n","corpus = pickle.load(open(corpus_file_path, 'rb'))\n","doc_lbls = pickle.load(open(doc_labels_file_path, 'rb'))\n","dtm_main = scipy.sparse.load_npz(dtm_file_path)\n","vocab = pickle.load(open(vocab_file_path, 'rb'))\n","\n","#preview the document labels\n","print('sample of document labels:', doc_lbls[:10])\n","print('sample of vocabulary:', vocab[:10])\n","print('dtm none zero count:', dtm_main.count_nonzero())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q0DpP0LLiFC7"},"outputs":[],"source":["# suppress the \"INFO\" messages and warnings from lda\n","logger = logging.getLogger('lda')\n","logger.addHandler(logging.NullHandler())\n","logger.propagate = False\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{"id":"QEjvXZP4MJgo"},"source":["## Model Evaluation Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Y1kepd2iQzx"},"outputs":[],"source":["#build a parameter inputs for the model using a scaling factor for eta and alpha\n","def build_param_inputs(kmax = 100, eta_factor = 1, alpha_factor = 1):\n","  #setup parameters\n","  const_params = {'n_iter': 500,'eta': round(0.1/eta_factor,5), 'random_state': 20191122}\n","  if kmax <=50:\n","   ks = list(range(5, kmax+1, 5))\n","  elif kmax <=100:\n","    ks = [5,10,15] + list(range(20, kmax+1, 10))\n","  else:\n","    ks = list(range(10, 100, 10)) + list(range(100, kmax+1, 20))\n","  varying_params = [dict(n_topics=k, alpha=round(1/(alpha_factor*k), 5)) for k in ks]\n","  num_trials = len(varying_params)\n","  #display the parameter selections\n","  print('[.] constant parameters:', const_params)\n","  print('[.] number of topics to try:', ks)\n","  print('[.] number of trials:', num_trials)\n","  print('[.] variable parameter trials:', varying_params)\n","\n","  return varying_params, const_params"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NEIc4Uipp6UI"},"outputs":[],"source":["#build a parameter inputs for the model using a fixed value for eta and alpha\n","def build_param_inputs_fixed(kmax = 100, eta_value = .1, alpha_value = 1):\n","  #setup parameters\n","  const_params = {'n_iter': 500,'eta': eta_value, 'random_state': 20191122}\n","  if kmax <=50:\n","   ks = list(range(5, kmax+1, 5))\n","  elif kmax <=100:\n","    ks = [5,10,15] + list(range(20, kmax+1, 10))\n","  else:\n","    ks = list(range(10, 100, 10)) + list(range(100, kmax+1, 20))\n","  varying_params = [dict(n_topics=k, alpha=alpha_value) for k in ks]\n","  num_trials = len(varying_params)\n","  #display the parameter selections\n","  print('[.] constant parameters:', const_params)\n","  print('[.] number of topics to try:', ks)\n","  print('[.] number of trials:', num_trials)\n","  print('[.] variable parameter trials:', varying_params)\n","\n","  return varying_params, const_params"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dZgq5Dfmi75r"},"outputs":[],"source":["#evaluate the model results for the model and return the performance metrics\n","def evaluate_model_results_custom(dtm_p, varying_p, const_p):\n","  #evaluate model results\n","  eval_results = tm_lda.evaluate_topic_models(dtm_p,\n","                                              varying_parameters = varying_p,\n","                                              constant_parameters = const_p,\n","                                              metric = ['arun_2010','cao_juan_2009','coherence_mimno_2011']\n","                                              )\n","  results_by_n_topics = results_by_parameter(eval_results, 'n_topics')\n","  results_by_n_topics = [(x, {key: round(value, 3) for key, value in inner_dict.items()}) for x, inner_dict in results_by_n_topics]\n","  #display the results of the models as text\n","  print('[.] number of results calculated:', len(results_by_n_topics))\n","  print('[.] results by n topic models:', results_by_n_topics)\n","\n","  return results_by_n_topics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q4O6LOK7jEOq"},"outputs":[],"source":["# plot the results of the model trials\n","#plot_eval_results(eval_results = results_by_n_topics, figsize=(8, 6))\n","#I cannot get this function to work for the life of me\n","#package conflict with version of pyplot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zkA7ZQBn-2Ih"},"outputs":[],"source":["#custom function to display the model results\n","def plot_eval_results_custom(results_by_n_topics):\n","  # Extract data from results_by_n_topics\n","  n_topics = [item[0] for item in results_by_n_topics]\n","  arun_2010_values = [item[1]['arun_2010'] for item in results_by_n_topics]\n","  cao_juan_2009_values = [item[1]['cao_juan_2009'] for item in results_by_n_topics]\n","  coherence_mimno_2011_values = [item[1]['coherence_mimno_2011'] for item in results_by_n_topics]\n","\n","  # Create subplots with a single row and multiple columns\n","  fig, axes = plt.subplots(1, 3, figsize=(12, 3))  # Adjust the figure size as needed\n","  fs = 8\n","\n","  # Plot Arun 2010 Metric\n","  axes[0].plot(n_topics, arun_2010_values, label='Arun 2010', marker='o')\n","  axes[0].set_xlabel('Number of Topics', fontsize=fs)\n","  axes[0].set_ylabel('Metric Value', fontsize=fs)\n","  axes[0].set_title('Minimize: Arun 2010', fontsize=fs)\n","\n","  # Plot Cao Juan 2009 Metric\n","  axes[1].plot(n_topics, cao_juan_2009_values, label='Cao Juan 2009', marker='o')\n","  axes[1].set_xlabel('Number of Topics', fontsize=fs)\n","  axes[1].set_ylabel('Metric Value', fontsize=fs)\n","  axes[1].set_title('Minimize: Cao Juan 2009', fontsize=fs)\n","\n","  # Plot Coherence Mimno 2011 Metric\n","  axes[2].plot(n_topics, coherence_mimno_2011_values, label='Coherence Mimno 2011', marker='o')\n","  axes[2].set_xlabel('Number of Topics', fontsize=fs)\n","  axes[2].set_ylabel('Metric Value', fontsize=fs)\n","  axes[2].set_title('Maximize: Coherence Mimno 2011', fontsize=fs)\n","\n","  # Adjust layout spacing\n","  plt.tight_layout()\n","\n","  # Show the plots\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L_GQpg91tW2v"},"outputs":[],"source":["#repeatable steps for completing a model evaluation with the variable parameters\n","def automate_test_varible_model(dtm_p, eta_list, alpha_list, kmax, output_file):\n","  #establish tracking metrics\n","  total_runs = len(eta_list) * len(alpha_list)\n","  all_model_runs = {}\n","  start_time = time.time()\n","  count = 0\n","  #iterate through all inputs for eta and alpha\n","\n","  for e in eta_list:\n","    for a in alpha_list:\n","      run_code = 'eta_factor_' + str(e).zfill(4) + '__' + 'alpha_factor_' + str(a).zfill(4)\n","      print('running the evaluation for:', run_code)\n","      #build the variable params\n","      varying_params, const_params = build_param_inputs(kmax = kmax, eta_factor = e, alpha_factor = a)\n","      #build the results\n","      results_by_n_topics = evaluate_model_results_custom(dtm_p = dtm_p, varying_p = varying_params, const_p = const_params)\n","      #record the results\n","      all_model_runs[run_code] = results_by_n_topics\n","      #update on the progress and runtime\n","      count += 1\n","      current_progress = int(round(count/total_runs,2)*100)\n","      current_runtime = round(time.time() - start_time,3)\n","      print('[-] current progress:', current_progress, '%', 'and a runtime of', current_runtime, 'seconds.')\n","      #plot the results\n","      plot_eval_results_custom(results_by_n_topics)\n","  #print summary of the entire run\n","  print('evaluation data captured for', len(all_model_runs), 'sets of parameters.')\n","  #save the files to disk\n","  eval_file_path = '%s/%s' % (DATA_DIR, output_file)\n","  pickle.dump(all_model_runs, open(eval_file_path, 'wb'))\n","  #return the results\n","  return all_model_runs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vWLIAjCjvhp6"},"outputs":[],"source":["#repeatable steps for completing a model evaluation with the fixed parameters\n","def automate_test_fixed_model(dtm_p, eta_list, alpha_list, kmax, output_file):\n","  #establish tracking metrics\n","  total_runs = len(eta_list) * len(alpha_list)\n","  all_model_runs = {}\n","  start_time = time.time()\n","  count = 0\n","  #iterate through all inputs for eta and alpha\n","\n","  for e in eta_list:\n","    for a in alpha_list:\n","      run_code = 'eta_' + str(e).zfill(4) + '__' + 'alpha_' + str(a).zfill(4)\n","      print('running the evaluation for:', run_code)\n","      #build the variable params\n","      varying_params, const_params = build_param_inputs_fixed(kmax = kmax, eta_value = e, alpha_value = a)\n","      #build the results\n","      results_by_n_topics = evaluate_model_results_custom(dtm_p = dtm_p, varying_p = varying_params, const_p = const_params)\n","      #record the results\n","      all_model_runs[run_code] = results_by_n_topics\n","      #update on the progress and runtime\n","      count += 1\n","      current_progress = int(round(count/total_runs,2)*100)\n","      current_runtime = round(time.time() - start_time,3)\n","      print('[-] current progress:', current_progress, '%', 'and a runtime of', current_runtime, 'seconds.')\n","      #plot the results\n","      plot_eval_results_custom(results_by_n_topics)\n","  #print summary of the entire run\n","  print('evaluation data captured for', len(all_model_runs), 'sets of parameters.')\n","  #save the files to disk\n","  eval_file_path = '%s/%s' % (DATA_DIR, output_file)\n","  pickle.dump(all_model_runs, open(eval_file_path, 'wb'))\n","  #return the results\n","  return all_model_runs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cffy5w8yvz8n"},"outputs":[],"source":["#load model evaluations previously saved in a file\n","def load_model_evaluations(DATA_DIR, path_location):\n","  #location of model evaluation file files\n","  eval_file_path = '%s/%s' % (DATA_DIR, path_location)\n","  #load the model\n","  all_model_runs = pickle.load(open(eval_file_path, 'rb'))\n","  #load the keys for the models\n","  model_keys = list(all_model_runs.keys())\n","  #preview the document labels\n","  print('all keys:', model_keys)\n","  #preview a sample of the model data\n","  print('sample of model data:', all_model_runs[model_keys[0]])\n","  # return the model data\n","  return all_model_runs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-9MMLEvGv-AS"},"outputs":[],"source":["#reprint the model evaluations\n","def print_model_evaluations(all_model_runs, limit = 1000, model_keys = None):\n","  if model_keys == None:\n","    key_list = list(all_model_runs.keys())\n","  else:\n","    key_list = model_keys\n","  len_to_print = min(len(key_list), limit)\n","  print('displaying charts for', len_to_print, 'models:\\n')\n","  count = 0\n","  for key in key_list:\n","    print ('model key:', key)\n","    plot_eval_results_custom(all_model_runs[key])\n","    print()\n","    count += 1\n","    if count >= limit:\n","      break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eyxyWkizv26w"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Fmpl_eUyiQs0"},"source":["## Round 1: Evaluate Model Options\n","\n","- [evaluate_topic_models()](https://tmtoolkit.readthedocs.io/en/latest/api.html#tmtoolkit.topicmod.tm_lda.evaluate_topic_models)\n","- [Guide: Evaluate Topic Model](https://tmtoolkit.readthedocs.io/en/latest/topic_modeling.html#Evaluation-of-topic-models)\n","- [tm_lda](https://tmtoolkit.readthedocs.io/en/latest/api.html#module-tmtoolkit.topicmod.tm_lda)\n","\n","A high alpha value indicates that each document contains most of the topics and on the contrary, a lower alpha value indicates that the documents are likely to contain a fewer number of topic.\n","\n","A Higher value of η indicates that the topics are likely to cover most of the words and on the contrary, lower eta value indicates that the topics are likely to contain a fewer number of words."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wxls56j-tdui"},"outputs":[],"source":["#define the input parameters\n","eta_list = [1]\n","alpha_list = [0.25, 0.5, 1, 2, 4]\n","#eta_list   = [0.5, 1, 2, 4, 8]\n","#alpha_list = [0.25, 0.5, 1, 2, 4]\n","kmax = 80\n","# run the function\n","all_model_runs = automate_test_varible_model(dtm_p = dtm_main,\n","                                           eta_list = eta_list,\n","                                           alpha_list = alpha_list,\n","                                           kmax = kmax,\n","                                           output_file = 'explore_eval_vary_ae_etaf_1o0_alphaf_list.p')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_mFgS270z7qx"},"outputs":[],"source":["#define the input parameters\n","eta_list = [2]\n","alpha_list = [0.25, 0.5, 1, 2, 4]\n","#eta_list   = [0.5, 1, 2, 4, 8]\n","#alpha_list = [0.25, 0.5, 1, 2, 4]\n","kmax = 80\n","# run the function\n","all_model_runs = automate_test_varible_model(dtm_p = dtm_main,\n","                                           eta_list = eta_list,\n","                                           alpha_list = alpha_list,\n","                                           kmax = kmax,\n","                                           output_file = 'explore_eval_vary_ae_etaf_2o0_alphaf_list.p')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"srAGkxOx4sNM"},"outputs":[],"source":["#define the input parameters\n","eta_list = [4]\n","alpha_list = [0.25, 0.5, 1, 2, 4]\n","#eta_list   = [0.5, 1, 2, 4, 8]\n","#alpha_list = [0.25, 0.5, 1, 2, 4]\n","kmax = 80\n","# run the function\n","all_model_runs = automate_test_varible_model(dtm_p = dtm_main,\n","                                           eta_list = eta_list,\n","                                           alpha_list = alpha_list,\n","                                           kmax = kmax,\n","                                           output_file = 'explore_eval_vary_ae_etaf_4o0_alphaf_list.p')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eBBcUMzx4y9f"},"outputs":[],"source":["#define the input parameters\n","eta_list = [0.5]\n","alpha_list = [0.25, 0.5, 1, 2, 4]\n","#eta_list   = [0.5, 1, 2, 4, 8]\n","#alpha_list = [0.25, 0.5, 1, 2, 4]\n","kmax = 80\n","# run the function\n","all_model_runs = automate_test_varible_model(dtm_p = dtm_main,\n","                                           eta_list = eta_list,\n","                                           alpha_list = alpha_list,\n","                                           kmax = kmax,\n","                                           output_file = 'explore_eval_vary_ae_etaf_0o5_alphaf_list.p')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ah-ZCPlCIICK"},"outputs":[],"source":["#define the input parameters\n","eta_list = [1]\n","alpha_list = [0.125, 0.25, 0.5]\n","#eta_list   = [0.5, 1, 2, 4, 8]\n","#alpha_list = [0.25, 0.5, 1, 2, 4]\n","kmax = 80\n","# run the function\n","all_model_runs = automate_test_varible_model(dtm_p = dtm_main,\n","                                           eta_list = eta_list,\n","                                           alpha_list = alpha_list,\n","                                           kmax = kmax,\n","                                           output_file = 'explore_eval_vary_ae_etaf_1o0_alphaf_list_r2.p')"]},{"cell_type":"markdown","metadata":{"id":"ruJMMbgQdn7B"},"source":["After reviewing many performance charts, a pattern emerged that an alpha_factor of 0.25 and 30 topics appers to perfrom well. There is more abiguity around what should be selected for eta. This will be explored in more detail in round 2."]},{"cell_type":"markdown","metadata":{"id":"4dr_yPL6rQDM"},"source":["## Round 2: Evaluate Model Options"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B-pcf9pgKvNP"},"outputs":[],"source":["#define the input parameters\n","eta_list = [0.125, 0.25, 0.5, 1, 2, 4, 8]\n","alpha_list = [0.25]\n","#eta_list   = [0.5, 1, 2, 4, 8]\n","#alpha_list = [0.25, 0.5, 1, 2, 4]\n","kmax = 80\n","# run the function\n","all_model_runs = automate_test_varible_model(dtm_p = dtm_main,\n","                                           eta_list = eta_list,\n","                                           alpha_list = alpha_list,\n","                                           kmax = kmax,\n","                                           output_file = 'explore_eval_vary_ae_etaf_list_r2_alphaf_0o25.p')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JDg4r1a3RpIN"},"outputs":[],"source":["#define the input parameters\n","eta_list = [0.20,0.25,0.30]\n","alpha_list = [0.20,0.25,0.30]\n","kmax = 80\n","# run the function\n","all_model_runs = automate_test_varible_model(dtm_p = dtm_main,\n","                                           eta_list = eta_list,\n","                                           alpha_list = alpha_list,\n","                                           kmax = kmax,\n","                                           output_file = 'explore_eval_vary_ae_etaf_list_r2_alphaf_list_r2.p')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iMm8UPPFZ1hi"},"outputs":[],"source":["#test loading data saved in a file to the all model objcet\n","#all_model_runs = load_model_evaluations(DATA_DIR = DATA_DIR, path_location = 'explore_eval_vary_ae_etaf_list_r2_alphaf_0o25.p')\n","#print()\n","#test the print function for 1 set of charts\n","#print_model_evaluations(all_model_runs = all_model_runs, limit = 1)"]},{"cell_type":"markdown","metadata":{"id":"F050iLk-eAR-"},"source":["Main parameter sets of interest:\n","- eta_factor_0001__alpha_factor_0.25 - 30 topics\n","- eta_factor_0.25__alpha_factor_0.25 - 30 topics\n","- eta_factor_0.25__alpha_factor_00.3"]},{"cell_type":"markdown","metadata":{"id":"bbpxm4rRGjDc"},"source":["## Round 3: Strategic Model Options"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eCeR6f6QGkyg"},"outputs":[],"source":["#model parameters\n","eta_factor = 1; alpha_factor = 0.25; k = 30\n","#claculate parameters\n","eta = round(0.1/eta_factor,5)\n","alpha = round(1/(alpha_factor*k), 5)\n","# run calculations and vizualize\n","varying_params, const_params = build_param_inputs_fixed(kmax = 60, eta_value = eta, alpha_value = alpha)\n","results_by_n_topics = evaluate_model_results_custom(dtm_p = dtm_main, varying_p = varying_params, const_p = const_params)\n","plot_eval_results_custom(results_by_n_topics)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oytTnckDfHai"},"outputs":[],"source":["#model parameters\n","eta_factor = 1; alpha_factor = 0.30; k = 30\n","#claculate parameters\n","eta = round(0.1/eta_factor,5)\n","alpha = round(1/(alpha_factor*k), 5)\n","# run calculations and vizualize\n","varying_params, const_params = build_param_inputs_fixed(kmax = 60, eta_value = eta, alpha_value = alpha)\n","results_by_n_topics = evaluate_model_results_custom(dtm_p = dtm_main, varying_p = varying_params, const_p = const_params)\n","plot_eval_results_custom(results_by_n_topics)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"APabhNljL6nj"},"outputs":[],"source":["#model parameters\n","eta_factor = 0.25; alpha_factor = 0.25; k = 30\n","#claculate parameters\n","eta = round(0.1/eta_factor,5)\n","alpha = round(1/(alpha_factor*k), 5)\n","# run calculations and vizualize\n","varying_params, const_params = build_param_inputs_fixed(kmax = 60, eta_value = eta, alpha_value = alpha)\n","results_by_n_topics = evaluate_model_results_custom(dtm_p = dtm_main, varying_p = varying_params, const_p = const_params)\n","plot_eval_results_custom(results_by_n_topics)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YqRWp5wKLxnO"},"outputs":[],"source":["#model parameters\n","eta_factor = 0.25; alpha_factor = 0.30; k = 30\n","#claculate parameters\n","eta = round(0.1/eta_factor,5)\n","alpha = round(1/(alpha_factor*k), 5)\n","# run calculations and vizualize\n","varying_params, const_params = build_param_inputs_fixed(kmax = 60, eta_value = eta, alpha_value = alpha)\n","results_by_n_topics = evaluate_model_results_custom(dtm_p = dtm_main, varying_p = varying_params, const_p = const_params)\n","plot_eval_results_custom(results_by_n_topics)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"28cYlQJvvbdh"},"outputs":[],"source":["# 'eta': 0.1  'alpha': 0.13333\n","#(30, {'arun_2010': 0.155, 'cao_juan_2009': 0.223, 'coherence_mimno_2011': -461.601})\n","\n","# 'eta': 0.1  'alpha': 0.11111\n","#(30, {'arun_2010': 0.162, 'cao_juan_2009': 0.237, 'coherence_mimno_2011': -462.157})\n","\n","# 'eta': 0.4  'alpha': 0.13333\n","#(30, {'arun_2010': 0.158, 'cao_juan_2009': 0.232, 'coherence_mimno_2011': -461.677})\n","\n","# 'eta': 0.4  'alpha': 0.11111\n","#(30, {'arun_2010': 0.158, 'cao_juan_2009': 0.25, 'coherence_mimno_2011': -453.226})"]},{"cell_type":"markdown","metadata":{"id":"wI74-SwTa9rc"},"source":["Base on detailed exploration, the following parameters appear to optimze the charts best:\n","- Number of Topics = 30\n","- Eta = 0.1\n","- Alpha = 1/25"]},{"cell_type":"markdown","metadata":{"id":"LCU8pQHxw5Fi"},"source":["## Round 4: Evaluate Model Options"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KZgYGHVGsNAj"},"outputs":[],"source":["# test loading data saved in a file to the all model objcet\n","all_model_runs = load_model_evaluations(DATA_DIR = DATA_DIR, path_location = 'explore_eval_fixed_eta_001.p')\n","print()\n","#test the print function for 1 set of charts\n","print_model_evaluations(all_model_runs = all_model_runs, limit = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rfsoaL4_HEMs"},"outputs":[],"source":["# print models of interest\n","'''\n","pl = ['explore_eval_fixed_eta_010.p',\n","'explore_eval_fixed_eta_008.p',\n","'explore_eval_fixed_eta_007.p',\n","'explore_eval_fixed_eta_006.p',\n","'explore_eval_fixed_eta_004.p',\n","'explore_eval_fixed_eta_004.p',\n","'explore_eval_fixed_eta_003.p']\n","ml = [['eta_00.1__alpha_00.2'],\n","['eta_0.08__alpha_00.5'],\n","['eta_0.07__alpha_00.4'],\n","['eta_0.06__alpha_00.1'],\n","['eta_0.04__alpha_00.6'],\n","['eta_0.04__alpha_00.4'],\n","['eta_0.03__alpha_00.2']]\n","\n","for p, m in zip (pl, ml):\n","  print(p, '-', m)\n","  all_model_runs = load_model_evaluations(DATA_DIR = DATA_DIR, path_location = p)\n","  print_model_evaluations(all_model_runs = all_model_runs, limit = 10, model_keys = m)\n","'''\n","print('skipped')"]},{"cell_type":"markdown","metadata":{"id":"GglxxFTwEeh0"},"source":["# 5.&nbsp;Model: Final"]},{"cell_type":"markdown","metadata":{"id":"Lkq_bLSniNAW"},"source":["## Import the Corpus"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jsXhBmbBXS9H"},"outputs":[],"source":["#location of corpus files\n","corpus_file_path = '%s/corpus.p' % DATA_DIR\n","doc_labels_file_path = '%s/doc_labels.p' % DATA_DIR\n","vocab_file_path = '%s/vocab.p' % DATA_DIR\n","dtm_file_path = '%s/dtm_main.npz' % DATA_DIR\n","\n","#load the corpus\n","corpus = pickle.load(open(corpus_file_path, 'rb'))\n","doc_labels_main = pickle.load(open(doc_labels_file_path, 'rb'))\n","dtm_main = scipy.sparse.load_npz(dtm_file_path)\n","vocab_main = pickle.load(open(vocab_file_path, 'rb'))"]},{"cell_type":"markdown","metadata":{"id":"kKLTUFppXPE5"},"source":["## Create the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TnUC80Vhcoqp"},"outputs":[],"source":["#model parameters\n","eta_factor = 1; alpha_factor = 0.25\n","#eta_factor = 0.25; alpha_factor = 0.35\n","k = 30\n","#claculate parameters\n","eta = round(0.1/eta_factor,5)\n","alpha = round(1/(alpha_factor*k), 5)\n","#display parameters for model\n","print('k:', k,'\\teta:', eta,'\\talpha:', alpha)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qpbjfEVtXtrq"},"outputs":[],"source":["# set data to use\n","dtms = {\n","    'main': dtm_main\n","}\n","\n","# and fixed hyperparameters\n","# Here, alpha represents document-topic density - with a higher alpha, documents\n","# are made up of more topics, and with lower alpha, documents contain fewer topics.\n","#Beta represents topic-word density - with a high beta, topics are made up of\n","#most of the words in the corpus, and with a low beta they consist of few words.\n","# https://www.thoughtvector.io/blog/lda-alpha-and-beta-parameters-the-intuition/\n","lda_params = {\n","    'n_topics': k,\n","    'eta': eta,\n","    'n_iter': 1000,\n","    'random_state': 20191122,  # to make results reproducible\n","    'alpha': alpha\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vrr9nFtbX-tn"},"outputs":[],"source":["#create the model\n","models = compute_models_parallel(dtms, constant_parameters=lda_params)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wHGSiYwZYGAE"},"outputs":[],"source":["#preview the model\n","model_main = models['main'][0][1]\n","print_ldamodel_topic_words(model_main.topic_word_, vocab_main, top_n=3)"]},{"cell_type":"markdown","metadata":{"id":"fCbqhoQ9d3Qk"},"source":["## Save Topic Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZPri7Gmxd1_z"},"outputs":[],"source":["#save the model to disk\n","model_file_path = '%s/main_model.p' % MODEL_DIR\n","\n","with open(model_file_path, \"wb\") as modelfile:\n","    save_ldamodel_to_pickle(modelfile, model_main, vocab_main, doc_labels_main, dtm=dtm_main)"]},{"cell_type":"markdown","metadata":{"id":"P_ch6h37Eekq"},"source":["# 6.&nbsp; Classify and Enrich Topic Data\n","\n","With a final topic model in place, topics can be assigned to documents to automatically cluster the review data by topic. Additional details can be added to the topic model to better filter and focus the dataset."]},{"cell_type":"markdown","metadata":{"id":"x17nHxZ8HOVt"},"source":["## Load the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F1M5oxq-HOeT"},"outputs":[],"source":["#build the paths\n","corpus_file_path = '%s/corpus.p' % DATA_DIR\n","model_file_path = '%s/main_model.p' % MODEL_DIR\n","text_file_path = '%s/corpus_raw_text.p' % DATA_DIR\n","#load the files\n","with open(corpus_file_path, \"rb\") as corpusfile:\n","    corpus = pickle.load(corpusfile)\n","with open(text_file_path, \"rb\") as textfile:\n","    corpus_raw_text = pickle.load(textfile)\n","with open(model_file_path, \"rb\") as modelfile:\n","    model_info = load_ldamodel_from_pickle(modelfile)\n","\n","#preview the model info keys\n","model_info.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yrma7CLLHuEF"},"outputs":[],"source":["#extract the parts of the model\n","model_main      = model_info[\"model\"]\n","vocab_main      = model_info[\"vocab\"]\n","dtm_main        = model_info[\"dtm\"]\n","doc_labels_main = model_info[\"doc_labels\"]"]},{"cell_type":"markdown","metadata":{"id":"utNNdIP_B6wA"},"source":["## Create Topic Names and Classification"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZIPyVDUZB7Mq"},"outputs":[],"source":["#create a function to create topic labels\n","def calc_topic_labels(dtm_p, model_p, vocab_p, lamda_p):\n","  #create the document lengths\n","  doc_lengths_main = doc_lengths(dtm_p)\n","  #create the topic label names\n","  topic_labels_main = generate_topic_labels_from_top_words(\n","                          model_p.topic_word_,\n","                          model_p.doc_topic_,\n","                          doc_lengths_main,\n","                          vocab_p,\n","                          lambda_=lamda_p,\n","                          n_words=4\n","                      )\n","  return topic_labels_main"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pC9Xx9xVHO6X"},"outputs":[],"source":["lambda_list = list(range(1,11))\n","lambda_list = [round(i/10,3) for i in lambda_list]\n","print(lambda_list)\n","\n","dict_topic_test = {}\n","\n","#generate topic labels with a variety of different lambdas and display in a table\n","for l in lambda_list:\n","    topic_labels_main = calc_topic_labels(dtm_p = dtm_main,\n","                                        model_p = model_main,\n","                                        vocab_p = vocab_main,\n","                                        lamda_p = l)\n","    key = 'model_lamdda_' + str(int(l*100)).zfill(3)\n","    dict_topic_test[key] = topic_labels_main\n","\n","df_dict_topic_test = pd.DataFrame(dict_topic_test)\n","df_dict_topic_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aGCO0BvvD999"},"outputs":[],"source":["lambda_list = list(range(6,13))\n","lambda_list = [round(i/20,3) for i in lambda_list]\n","print(lambda_list)\n","\n","dict_topic_test = {}\n","\n","#generate topic labels with a variety of different lambdas and display in a table\n","for l in lambda_list:\n","    topic_labels_main = calc_topic_labels(dtm_p = dtm_main,\n","                                        model_p = model_main,\n","                                        vocab_p = vocab_main,\n","                                        lamda_p = l)\n","    key = 'model_lamdda_' + str(int(l*100)).zfill(3)\n","    dict_topic_test[key] = topic_labels_main\n","\n","df_dict_topic_test = pd.DataFrame(dict_topic_test)\n","df_dict_topic_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"80KSq8gbFFvQ"},"outputs":[],"source":["  #create the final topics labels for the topic model\n","  topic_labels_main = calc_topic_labels(dtm_p = dtm_main,\n","                                        model_p = model_main,\n","                                        vocab_p = vocab_main,\n","                                        lamda_p = 0.4)\n","\n","  #display the list of topic labels\n","  print('created topic labels:')\n","  print(topic_labels_main)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gbBZTJVuFau0"},"outputs":[],"source":["# Topic Model Coherence\n","from tmtoolkit.topicmod.evaluate import metric_coherence_mimno_2011\n","\n","# use top 20 words per topic for metric\n","coh = metric_coherence_mimno_2011(model_main.topic_word_, dtm_main, top_n=10, include_prob=True)\n","print(coh, '\\n')\n","\n","\n","#display a histogram of the coherence\n","plt.hist(coh, bins=20)\n","plt.xlabel('coherence')\n","plt.ylabel('n')\n","plt.show();\n","\n","#print the best and worst topics according to this metric\n","top10_t_indices = np.argsort(coh)[::-1][:10]\n","bottom10_t_indices = np.argsort(coh)[:10]\n","\n","print('\\ntop 10 topics:', topic_labels_main[top10_t_indices])\n","print('\\nbottom 10 topics:', topic_labels_main[bottom10_t_indices])"]},{"cell_type":"markdown","metadata":{"id":"trFWfb6_HBUe"},"source":["## Classify the Documents"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WfmM1TqSDu84"},"outputs":[],"source":["#classify each document with the label\n","doc_topic_main = model_main.doc_topic_\n","documentclassifications = ldamodel_top_doc_topics(doc_topic_main,\n","                                                  doc_labels_main,\n","                                                  top_n=3,\n","                                                  topic_labels=topic_labels_main)\n","#preview the document classifications\n","documentclassifications.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XwRDDK3Agdv2"},"outputs":[],"source":["#add details from the dicument to label table\n","documentclassifications['rank_1_topic'] = [i.split(' ')[0]for i in documentclassifications['rank_1']]\n","documentclassifications['rank_1_prob'] = [float(i.split(' ')[1][1:-1]) for i in documentclassifications['rank_1']]\n","documentclassifications['rank_2_topic'] = [i.split(' ')[0] for i in documentclassifications['rank_2']]\n","documentclassifications['rank_2_prob'] = [float(i.split(' ')[1][1:-1]) for i in documentclassifications['rank_2']]\n","documentclassifications['rank_3_topic'] = [i.split(' ')[0] for i in documentclassifications['rank_3']]\n","documentclassifications['rank_3_prob'] = [float(i.split(' ')[1][1:-1]) for i in documentclassifications['rank_3']]\n","#drop the combined columns\n","documentclassifications = documentclassifications.drop(columns = ['rank_1','rank_2','rank_3'])\n","#preview the document classifications\n","documentclassifications.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SIUpvLFEkeGP"},"outputs":[],"source":["#plot the distribution of rank 1 topics\n","sns.distplot(documentclassifications['rank_1_prob'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qs1C_1hDk46c"},"outputs":[],"source":["#plot the probability distribution for topics (rank 1 - rank 3)\n","sns.set(color_codes=True)\n","sns.set(style=\"white\", palette=\"muted\")\n","sns.histplot(documentclassifications[['rank_1_prob','rank_2_prob','rank_3_prob']],\n","             kde=True,\n","             stat=\"percent\",\n","             binwidth = 0.02)"]},{"cell_type":"markdown","metadata":{"id":"HF2AESqQaVxm"},"source":["## Enrich Data with Review Info"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kzBFV66SZdU7"},"outputs":[],"source":["#this assigns the filename we're trying to load\n","allnikereviews_file_path = '%s/allnikereviews.json' % DATA_DIR\n","json_file = json.load(open(allnikereviews_file_path, 'r'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AyutXTVnZdvT"},"outputs":[],"source":["#extract fields from all review details\n","reviews = []\n","asin = []\n","overall_rating = []\n","reviewer_id = []\n","\n","#extract review details to add to the tagged documents\n","for a_review in json_file:\n","    the_review = json_file[a_review]\n","    reviews.append(the_review[\"reviewText\"])\n","    asin.append(the_review[\"asin\"])\n","    overall_rating.append(the_review[\"overall\"])\n","    reviewer_id.append(the_review[\"reviewerID\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DvGpGViJEig7"},"outputs":[],"source":["#add details from the dicument to label table\n","documentclassifications['text'] = reviews\n","documentclassifications['asin'] = asin\n","documentclassifications['overall_rating'] = overall_rating\n","documentclassifications['reviewer_id'] = reviewer_id\n","#preview the document classifications\n","documentclassifications.head()"]},{"cell_type":"markdown","metadata":{"id":"eff78b68OalV"},"source":["## Enrich the Data with Product Info"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_z0_zGqaOZZU"},"outputs":[],"source":["#this assigns the filename we're trying to load\n","allnikeproducts_file_path = '%s/allnikeproducts.p' % DATA_DIR\n","allnikeproducts = pickle.load(open(allnikeproducts_file_path, 'rb'))\n","\n","allnikeproducts['B0000V9K32']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wT-bkXCpVuMP"},"outputs":[],"source":["nike_asin_list = list(documentclassifications['asin'])\n","print(nike_asin_list[1:5])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DFVF3qxLWpTt"},"outputs":[],"source":["allnikeproducts['B0000V9K32']['salesRank']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5fc8gSgmW3vm"},"outputs":[],"source":["allnikeproducts[nike_asin_list[0]]['salesRank'].keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bVjcHV5JVxiV"},"outputs":[],"source":["sale_category = []\n","sale_rank = []\n","title = []\n","\n","#extract out product details to add to the tagged documents\n","for asin in nike_asin_list:\n","    #print(asin)\n","    the_product = allnikeproducts[asin]\n","    #print(the_product)\n","    if the_product.get(\"salesRank\"):\n","      sale_category.append(list(allnikeproducts[asin]['salesRank'].keys())[0])\n","      sale_rank.append(list(allnikeproducts[asin]['salesRank'].values())[0])\n","    else:\n","      sale_category.append('Unknown')\n","      sale_rank.append(None)\n","    title.append(the_product['title'])\n","\n","#add details from the dicument to label table\n","documentclassifications['sale_category'] = sale_category\n","documentclassifications['sale_rank'] = sale_rank\n","documentclassifications['title'] = title\n","#preview the document classifications\n","documentclassifications.head()"]},{"cell_type":"markdown","metadata":{"id":"olAt74-uadGF"},"source":["## Enrich Data with Sentiment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gEM4no3babaV"},"outputs":[],"source":["#create a function to get the sentiment of a list of text\n","def get_sentiment_texts(texts):\n","    \"\"\"Implement this function which should take a list of texts\n","    and returns 2 lists with the sentiment polarity\n","\n","    See the TextBlob documentation for how to evaluate sentiment. For our\n","    purposes here, negative sentiment is a sentiment with polarity < 0.0.\n","    \"\"\"\n","    texts_length = len(texts)\n","    sentiments = [None] * texts_length\n","    results = []\n","    print('processing sentiments for', texts_length, 'texts:')\n","    for t, i in zip(texts, range(len(texts))):\n","      text = TextBlob(t)\n","      sentiments[i] = text.sentiment.polarity\n","\n","    return sentiments"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xAsyHTNHbAlg"},"outputs":[],"source":["#add details from the dicument to label table\n","documentclassifications['sentiment'] = get_sentiment_texts(list(documentclassifications['text']))\n","#add flag for sentiment\n","documentclassifications['positive_sentiment'] = [i >= 0 for i in documentclassifications['sentiment']]\n","documentclassifications['negative_sentiment'] = [i < 0 for i in documentclassifications['sentiment']]\n","#add overal rating categories\n","documentclassifications['overall_rating_low'] = [i <= 2 for i in documentclassifications['overall_rating']]\n","documentclassifications['overall_rating_high'] = [i >= 4 for i in documentclassifications['overall_rating']]\n","#preview the document classifications\n","documentclassifications.head(3)"]},{"cell_type":"markdown","metadata":{"id":"ibu98y4iFt_W"},"source":["## Preview Samples from Topic Labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tfsjCEHBEsRt"},"outputs":[],"source":["#preview the topic labels for a sample record\n","k = 901\n","documentclassifications.loc[k]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BSNluClxE5Yo"},"outputs":[],"source":["#preview the full text for the sample record\n","documentclassifications.loc[k]['text']"]},{"cell_type":"markdown","metadata":{"id":"oIxjqN3IFyak"},"source":["## Export the Topic Labels to Excel"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wJjnTyC3FMWP"},"outputs":[],"source":["#export the topic classification data to excel\n","topic_excel_path = '%s/topics.documentclassification.xlsx' % DATA_DIR\n","documentclassifications.to_excel(topic_excel_path)"]},{"cell_type":"markdown","metadata":{"id":"ECRMa1527UUD"},"source":["# 7.&nbsp; Model Evaluation"]},{"cell_type":"markdown","metadata":{"id":"J1ZSDm-GFpZK"},"source":["## Visualize the Topics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xO5ry-ZzF1Fj"},"outputs":[],"source":["#create parameters for ldavis\n","ldavis_params = parameters_for_ldavis(model_main.topic_word_,\n","                                      model_main.doc_topic_,\n","                                      dtm_main,\n","                                      vocab_main)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wl_bL4G1F1MD"},"outputs":[],"source":["#plot the distance map\n","%matplotlib inline\n","vis = pyLDAvis.prepare(**ldavis_params)\n","pyLDAvis.enable_notebook(local=True)\n","pyLDAvis.display(vis)"]},{"cell_type":"markdown","metadata":{"id":"thyXSub1dIFC"},"source":["## Vizualize Segmentations"]},{"cell_type":"markdown","metadata":{"id":"yq9MpdxHsX9W"},"source":["### Overview of Sales Categories"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jMzwhM7EdzBp"},"outputs":[],"source":["#plot the distribution of reviews across the different sales categories\n","sns.countplot(data=documentclassifications, y=\"sale_category\")"]},{"cell_type":"markdown","metadata":{"id":"tjcFijs0sjq8"},"source":["### Top 5 Products Most Negative Sentiment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rokAMDLzUKVp"},"outputs":[],"source":["#create a table of the top negative sentiment products\n","df_asin = documentclassifications[['asin','title', 'sentiment']]\n","df_asin = df_asin[df_asin['sentiment'] < 0]\n","df_asin = df_asin.groupby(['asin','title']).agg(['mean','count']).reset_index()\n","df_asin.columns = ['_'.join(col) for col in df_asin.columns]\n","df_asin = df_asin.rename(columns={'asin_': 'asin', 'title_': 'title', 'sentiment_count': 'count'})\n","df_asin = df_asin[df_asin['count'] >= 10]\n","df_asin = df_asin.sort_values(by=['count'], ascending=False)\n","df_asin = df_asin.head(5)\n","df_asin"]},{"cell_type":"markdown","metadata":{"id":"rreVIDAfxS_B"},"source":["### Top 5 Topics Most Negative Sentiment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Iw_jIOixSjL"},"outputs":[],"source":["#adjust properties to display all text\n","pd.set_option('display.max_colwidth', -1)\n","print(pd.get_option(\"display.max_colwidth\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E9T1h8ANUA9Q"},"outputs":[],"source":["#focus on a specific product and display negative review text for the product\n","df_prod_dtl = documentclassifications[documentclassifications['asin'] == 'B007FXKMLW']\n","df_prod_dtl = df_prod_dtl[df_prod_dtl['sentiment'] < 0]\n","df_prod_dtl = df_prod_dtl[df_prod_dtl['overall_rating'] < 3]\n","df_prod_dtl = df_prod_dtl[df_prod_dtl['rank_1_prob'] >= 0.3]\n","df_prod_dtl = df_prod_dtl.sort_values(by=['rank_1_topic', 'sentiment'], ascending=True).reset_index()\n","df_prod_dtl = df_prod_dtl[['asin','title', 'sale_category', 'overall_rating', 'sentiment',\n","                           'rank_1_topic', 'rank_1_prob', 'text']]\n","df_prod_dtl.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3cDU3KDDv2kz"},"outputs":[],"source":["#Return Properties to default\n","pd.reset_option(\"display.max_colwidth\")\n","print(pd.get_option(\"display.max_colwidth\"))"]},{"cell_type":"markdown","metadata":{"id":"II3TIZmcxeOm"},"source":["### Sentiment vs. Category Across Sale Categories"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e0DMGpQzdIOU"},"outputs":[],"source":["#segment data acrtoss 3 categories of the sales category field\n","dc_shoes = documentclassifications[documentclassifications['sale_category'] == 'Shoes']\n","dc_watches = documentclassifications[documentclassifications['sale_category'] == 'Watches']\n","dc_other = documentclassifications[(documentclassifications['sale_category'] != 'Shoes')\n","                                   & (documentclassifications['sale_category'] != 'Watches')]\n","#display plots for the distribution of sentiment across each overall rating level\n","f, axes = plt.subplots(1,3, figsize=(12, 4))\n","min_lim = -1.25; max_lim = 1.25\n","axes[0].set(ylim=(min_lim, max_lim)); axes[1].set(ylim=(min_lim, max_lim)); axes[2].set(ylim=(min_lim, max_lim))\n","sns.violinplot(data=dc_shoes, x=\"overall_rating\", y=\"sentiment\", ax=axes[0]).set(title='Shoes Sales Category')\n","sns.violinplot(data=dc_watches, x=\"overall_rating\", y=\"sentiment\", ax=axes[1]).set(title='Watches Sales Category')\n","sns.violinplot(data=dc_other, x=\"overall_rating\", y=\"sentiment\", ax=axes[2]).set(title='Not Shoes & Watched Sales Category')"]},{"cell_type":"markdown","metadata":{"id":"LVwfWkK2xn-t"},"source":["### Heatmap of Topics vs. Categories"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"blCS0sx_hrXL"},"outputs":[],"source":["#summarize the tagged documents into their rank_1 topics with aggregate metrics\n","df_sum_cats = documentclassifications[['sale_category','rank_1_topic', 'sentiment']]\n","df_sum_cats = df_sum_cats.groupby(['sale_category','rank_1_topic']).agg(['min','mean','max','count']).reset_index()\n","df_sum_cats.columns = ['_'.join(col) for col in df_sum_cats.columns]\n","df_sum_cats = df_sum_cats.rename(columns={'sale_category_': 'sale_category', 'rank_1_topic_': 'rank_1_topic', 'sentiment_count': 'count'})\n","df_sum_cats['sale_category_count'] = df_sum_cats.groupby('sale_category')['count'].transform('sum')\n","df_sum_cats['pct_of_sales_category'] = df_sum_cats['count'] / df_sum_cats['sale_category_count']\n","df_sum_cats.head(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WXvxiE1Yl0AV"},"outputs":[],"source":["#summarize the columns in the table\n","df_sum_cats.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fz8U-3PLji_h"},"outputs":[],"source":["#plot a heatmap of what topics relate to what sales categories\n","df_heat = df_sum_cats[['sale_category','rank_1_topic', 'pct_of_sales_category']].pivot(\"rank_1_topic\", \"sale_category\", \"pct_of_sales_category\")\n","f, axes = plt.subplots(1,1, figsize=(12, 11))\n","sns.heatmap(data=df_heat, cmap=\"YlGnBu\", annot=True, fmt='.2f', ax=axes)"]},{"cell_type":"markdown","metadata":{"id":"7h7A9btzxzhk"},"source":["### Explore Extended List of Words for Topics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5xnOelLQHckw"},"outputs":[],"source":["#create the top topic words for each topic in the model and add to table\n","from tmtoolkit.topicmod.model_io import ldamodel_top_topic_words\n","\n","top_topic_word = ldamodel_top_topic_words(model_main.topic_word_,\n","                                          vocab_main,\n","                                          row_labels=topic_labels_main,\n","                                          top_n=15,\n","                                          val_fmt = '{lbl}').reset_index()\n","top_topic_word['rank_1'] = [i.split(' ')[0] for i in top_topic_word['rank_1']]\n","\n","top_topic_word[top_topic_word['topic'] == '7_pair_last_year_month']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W6W6pmqfJJnD"},"outputs":[],"source":["#sample of the top topic owrds dataframe\n","top_topic_word[top_topic_word['topic'] == '7_pair_last_year_month'].values.tolist()[0][1:]"]},{"cell_type":"markdown","metadata":{"id":"QwINudtXyBhk"},"source":["###Negative Sentiment Proportion"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aclNsxipQs7V"},"outputs":[],"source":["# Determine Percent Negative for Rank 1 Topics\n","df_sent_count = documentclassifications[['rank_1_topic', 'sentiment', 'positive_sentiment', 'negative_sentiment']]\n","df_sent_count = df_sent_count.drop(columns = ['sentiment'])\n","df_sent_count = df_sent_count.groupby(['rank_1_topic']).agg(['sum', 'count']).reset_index()\n","df_sent_count.columns = ['_'.join(col) for col in df_sent_count.columns]\n","df_sent_count = df_sent_count.drop(columns = ['positive_sentiment_count'])\n","df_sent_count = df_sent_count.rename(columns={'rank_1_topic_': 'rank_1_topic',\n","                                          'negative_sentiment_count': 'total_count',\n","                                          'positive_sentiment_sum': 'positive_sentiment',\n","                                          'negative_sentiment_sum': 'negative_sentiment'})\n","df_sent_count['pct_neg_sentiment'] = df_sent_count['negative_sentiment'] / df_sent_count['total_count']\n","df_sent_count['pct_neg_sentiment'] = [round(i,3) for i in df_sent_count['pct_neg_sentiment']]\n","df_sent_count = df_sent_count.sort_values(by=['pct_neg_sentiment'], ascending=False)\n","df_sent_count.head(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Aqcu5DkjasH_"},"outputs":[],"source":["# Mean Rating for Rank 1\n","df_or = documentclassifications[['rank_1_topic', 'overall_rating']]\n","df_or = df_or.groupby(['rank_1_topic']).agg(['mean', 'count']).reset_index()\n","df_or.columns = ['_'.join(col) for col in df_or.columns]\n","df_or = df_or.rename(columns={'rank_1_topic_': 'rank_1_topic',\n","                              'overall_rating_count': 'total_count'})\n","df_or['overall_rating_mean'] = [round(i,2) for i in df_or['overall_rating_mean']]\n","df_or = df_or.sort_values(by=['overall_rating_mean'], ascending=True)\n","df_or.head(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fe78L9rsz8lb"},"outputs":[],"source":["# Count Low and High Overall Rating Rating for Rank 1\n","df_or_cat = documentclassifications[['rank_1_topic', 'overall_rating_low', 'overall_rating_high']]\n","df_or_cat = df_or_cat.groupby(['rank_1_topic']).agg(['sum']).reset_index()\n","df_or_cat.columns = ['_'.join(col) for col in df_or_cat.columns]\n","df_or_cat = df_or_cat.rename(columns={'rank_1_topic_': 'rank_1_topic',\n","                              'overall_rating_low_sum': 'overall_rating_low',\n","                              'overall_rating_high_sum': 'overall_rating_high',})\n","df_or_cat['pct_low_rating'] = df_or_cat['overall_rating_low'] / (df_or_cat['overall_rating_low'] + df_or_cat['overall_rating_high'])\n","df_or_cat['pct_low_rating'] = [round(i,3) for i in df_or_cat['pct_low_rating']]\n","df_or_cat = df_or_cat.sort_values(by=['pct_low_rating'], ascending=False)\n","df_or_cat.head(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CSkEllUO_w4G"},"outputs":[],"source":["# calculate the top topic words and create the base of the topic summary metric table\n","df_sum_rank = documentclassifications[['rank_1_topic', 'sentiment']]\n","df_sum_rank = df_sum_rank.groupby(['rank_1_topic']).agg(['min','mean','max','count']).reset_index()\n","df_sum_rank.columns = ['_'.join(col) for col in df_sum_rank.columns]\n","df_sum_rank = df_sum_rank.rename(columns={'rank_1_topic_': 'rank_1_topic', 'sentiment_count': 'count'})\n","df_sum_rank['total_count'] = df_sum_rank['count'].sum()\n","df_sum_rank['pct_of_total'] = df_sum_rank['count'] / df_sum_rank['total_count']\n","#round the numeric columns in the table\n","df_sum_rank['pct_of_total'] = [round(i,3) for i in df_sum_rank['pct_of_total']]\n","df_sum_rank['sentiment_min'] = [round(i,3) for i in df_sum_rank['sentiment_min']]\n","df_sum_rank['sentiment_mean'] = [round(i,3) for i in df_sum_rank['sentiment_mean']]\n","df_sum_rank['sentiment_max'] = [round(i,3) for i in df_sum_rank['sentiment_max']]\n","#sort the table\n","df_sum_rank = df_sum_rank.sort_values(by=['sentiment_mean'], ascending=True)\n","#add list of topic words\n","df_sum_rank['top_topic_words'] = [top_topic_word[top_topic_word['topic'] == i].values.tolist()[0][1:] for i in df_sum_rank['rank_1_topic']]\n","#preview data\n","df_sum_rank.head(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"96U1JPguHXjM"},"outputs":[],"source":["#join the different metric tables into a single table\n","df_sum_rank = df_sum_rank.merge(df_or_cat[['pct_low_rating', 'rank_1_topic']], on = 'rank_1_topic', how = 'left')\n","df_sum_rank = df_sum_rank.merge(df_or[['overall_rating_mean', 'rank_1_topic']], on = 'rank_1_topic', how = 'left')\n","df_sum_rank = df_sum_rank.merge(df_sent_count[['pct_neg_sentiment', 'rank_1_topic']], on = 'rank_1_topic', how = 'left')\n","df_sum_rank = df_sum_rank.drop(columns=['sentiment_min','sentiment_max','total_count'])\n","df_sum_rank.head(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I36coNlfJc0x"},"outputs":[],"source":["#normalize the sentiment metrics and compute a combined score\n","df_sum_rank['pct_neg_sentiment_norm'] = MinMaxScaler().fit_transform(np.array(df_sum_rank['pct_neg_sentiment']).reshape(-1,1))\n","df_sum_rank['overall_rating_mean_norm'] = MinMaxScaler().fit_transform(np.array(df_sum_rank['overall_rating_mean']).reshape(-1,1))\n","df_sum_rank['pct_low_rating_norm'] = MinMaxScaler().fit_transform(np.array(df_sum_rank['pct_low_rating']).reshape(-1,1))\n","df_sum_rank['sentiment_mean_norm'] = 1 - MinMaxScaler().fit_transform(np.array(df_sum_rank['sentiment_mean']).reshape(-1,1))\n","df_sum_rank['neg_view_score'] = (df_sum_rank['pct_neg_sentiment_norm'] + df_sum_rank['overall_rating_mean_norm'] + df_sum_rank['pct_low_rating_norm'] + df_sum_rank['sentiment_mean_norm']) / 4\n","df_sum_rank['neg_view_score'] = [round(i,3) for i in df_sum_rank['neg_view_score']]\n","df_sum_rank['neg_view_score'] = MinMaxScaler().fit_transform(np.array(df_sum_rank['neg_view_score']).reshape(-1,1))\n","df_sum_rank = df_sum_rank.sort_values(by=['neg_view_score'], ascending=False).reset_index()\n","bottom_5_topics = df_sum_rank['rank_1_topic'].head(5)\n","top_5_topics = df_sum_rank['rank_1_topic'].tail(5)\n","df_sum_rank.head(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J2WfkQl5Ko6U"},"outputs":[],"source":["# plot the distribution of topic tags by negative review score metric\n","sns.set(color_codes=True)\n","sns.set(style=\"white\", palette=\"muted\")\n","sns.histplot(df_sum_rank['neg_view_score'],\n","             kde=True,\n","             stat=\"percent\",\n","             binwidth = 0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PTC84ac9IGRp"},"outputs":[],"source":["#displaty topic world list for an example topic in the model\n","print(df_sum_rank[df_sum_rank['rank_1_topic'] == '2_great_look_awesome_fit']['top_topic_words'])"]},{"cell_type":"markdown","metadata":{"id":"A5-SDjtqc5oN"},"source":["## Investigate: Shoe Sizing"]},{"cell_type":"markdown","metadata":{"id":"2wEkevn-Q0cd"},"source":["### Select a Problem\n","\n","Based on the sorted list, we can view the bottom 5 topics for Nike. For some topics (like 30_return_send_seller_item and 5_review_try_bad_problem) there is little Nike can do to resolve the problem. These are related to the buying experience where the customer had general issues and needed to return the item or bought an item that was already poorly reviewed. These can both be issues they work with their sales partner (Amazon) to resolve.\n","\n","For this investigation, we will focus on the topic **23_size_small_half_large** to better understand the scope and how we can imporve the product or the customer experience."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zmKU6flmNfsZ"},"outputs":[],"source":["#display the bottom 5 topics\n","bottom_5_topics"]},{"cell_type":"markdown","metadata":{"id":"i_FJRclZSLS5"},"source":["### Focus on the Data\n","\n","Using the enriched data, focus on the specific topic, and limit records for instances where the topic probability is above 30% to ensure the review is more likely to be talking about the topic."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tVQkF5TON6jW"},"outputs":[],"source":["#filter reviews to focus\n","target = bottom_5_topics[1]\n","print('the target for analysis will be:', target)\n","df_focus_prblm = documentclassifications[documentclassifications['rank_1_topic'] == target]\n","df_focus_prblm = df_focus_prblm[df_focus_prblm['rank_1_prob'] >= 0.3]\n","df_focus_prblm = df_focus_prblm[['rank_1_topic','rank_1_prob', 'sentiment', 'asin', 'sale_category', 'title', 'text']]\n","\n","print('collected', len(df_focus_prblm), 'reviews for analysis of', target)"]},{"cell_type":"markdown","metadata":{"id":"e1sMhJG9Sb8z"},"source":["To improve focus of the analysis, we can focus on a single sales category, shoes, that dominates the records in this topic."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lmpjeNTIQL7n"},"outputs":[],"source":["#plot the sales categories to see if there is a main product\n","sns.countplot(data=df_focus_prblm, y=\"sale_category\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TGnnujrhQVmT"},"outputs":[],"source":["#filter problem category to only focus on shoes\n","df_focus_prblm = df_focus_prblm[df_focus_prblm['sale_category'] == 'Shoes']"]},{"cell_type":"markdown","metadata":{"id":"-EERLWyfSq_V"},"source":["### Review the Top Products in the Topic"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0M45dzPOSrJQ"},"outputs":[],"source":["#slice of data table focused on uniqu products in the problem topic\n","df_prod_count = df_focus_prblm[['title', 'sentiment']]\n","df_prod_count = df_prod_count.groupby(['title']).agg(['mean', 'count']).reset_index()\n","df_prod_count.columns = ['_'.join(col) for col in df_prod_count.columns]\n","df_prod_count = df_prod_count.rename(columns={'title_': 'title', 'sentiment_count': 'count'})\n","df_prod_count = df_prod_count.sort_values(by=['count'], ascending=False).reset_index()\n","df_prod_count['sentiment_mean'] = [round(i,3) for i in df_prod_count['sentiment_mean']]\n","df_prod_count['title'] = [i[:50] for i in df_prod_count['title']]\n","print('there are', len(df_prod_count), 'unique products that are part of this category')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5ZGWwM0TThb6"},"outputs":[],"source":["#products with a count abive threshold for the topic\n","print('some of the top products:')\n","df_prod_count = df_prod_count[df_prod_count['count'] >= 5]\n","df_prod_count"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Iw3X10kTOUC"},"outputs":[],"source":["#Most common products in the topic\n","f, ax = plt.subplots(1,1, figsize=(6, 6))\n","sns.set_context('paper', font_scale = 0.9)\n","ax = sns.barplot(data=df_prod_count.head(10), y='title', x = 'count', width=.8, ax=ax)\n","plt.figure()"]},{"cell_type":"markdown","metadata":{"id":"bEsHHkgxagGg"},"source":["### What Are People Saying"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2_DnJSlQPEzu"},"outputs":[],"source":["#best 10 reviews for topic\n","df_focus_prblm.sort_values(by=['sentiment'], ascending=False).reset_index().head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cJjnrm9YPMu8"},"outputs":[],"source":["#worst 10 reviews for topic\n","df_focus_prblm.sort_values(by=['sentiment'], ascending=True).reset_index().head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-5KNzpDHFFt0"},"outputs":[],"source":["#lookup where reviews talk about battery issues\n","#print('Results:')\n","#lookup = documentclassifications[documentclassifications['text'].str.contains('battery')]\n","#lookup.head(5)"]},{"cell_type":"markdown","metadata":{"id":"jhbcV2BkGk8d"},"source":["### Generate Topic Wordcloud"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qLH9zmSMGlFx"},"outputs":[],"source":["# some options for wordcloud output\n","img_w = 400   # image width\n","img_h = 300   # image height\n","\n","topic_clouds = generate_wordclouds_for_topic_words(\n","    model_main.topic_word_, vocab_main,\n","    top_n=20, topic_labels=topic_labels_main,\n","    width=img_w, height=img_h\n",")\n","\n","# show all generated word clouds\n","topic_clouds.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mu45cqpKHDLI"},"outputs":[],"source":["#display wordcloud for a topic\n","topic_clouds['23_size_small_half_large']"]},{"cell_type":"markdown","metadata":{"id":"cXHvb30HEend"},"source":["# 8.&nbsp; Results"]},{"cell_type":"markdown","metadata":{"id":"nEkBb_phaxVb"},"source":["**Model**\n","\n","The final Topic Model produced 30 topics that clusted the Nike brand reviews into groups. After completing a sentiment analysis, the following clusters were the top 5 positive and negative clusters.\n","\n","|Rank| |Positive| |Negative|\n","|----|--|--------|--|--------|\n","| 1  | |21_compliment_lot_stylish_get| |30_return_send_seller_item|\n","| 2  | |25_light_weight_training_workout| |23_size_small_half_large|\n","| 3  | |19_fast_delivery_arrive_condition| |4_toe_narrow_lace_bit|\n","| 4  | |29_color_love_bright_super| |5_review_try_bad_problem |\n","| 5  | |2_great_look_awesome_fit| |7_pair_last_year_month|\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TExEHLHXb9Wn"},"outputs":[],"source":["#bottom_5_topics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1pHBkVxjb-Jr"},"outputs":[],"source":["#top_5_topics"]},{"cell_type":"markdown","metadata":{"id":"cxoX_WXOcoI9"},"source":["After completing a deep dive into the topic of 23_size_small_half_large. Overall customers were mostly talking about he fit of shoes in this category and that they either (1) new to size up a half size larger or (2) received shoes and wished they sized up a half size larger. We were able to identify some additional insights for Nike that groups into 3 key categories:\n","- Experienced Customers\n","- Customer Experience and Support\n","- Product Opportunity"]},{"cell_type":"markdown","metadata":{"id":"4-MiI3TreCVG"},"source":["**Experienced Customers**\n","\n","Generally speaking, customers who knew the Nike brand, knew to size-up when buying shoes. While they talked about this topic, they tended to order the correct size, have a more positive sentiment in their review, and provide a positive rating (4 or 5). What can be taken away from this is that the Nike brand can be challenging for new customers, especially when shopping online. Perhaps marketing spending for new customers should be focused more on getting that new customer into a store to get their initial brand experience."]},{"cell_type":"markdown","metadata":{"id":"Xb9ee_Poes3z"},"source":["**Customer Experience and Support**\n","\n","Customers who order their \"correct\" shoe size and get shoes that don't fit are frustrated. They generally provide a negative rating (1 or 2) and have a low or negative sentiment. This is not a good customer experience, but based on the experienced customer reviews, this appears to be preventable. Nike should invest in text, images, apps, etc. that can better support customers in selecting the best size of shoe. If they can get a customer to order the correct size, they are more likely to have a happy customer. As seen by both posititve and negative reviews grouped together, the topic isn't inherently negative. Customers are ok with the fact that product runs small, they simply are frustrated and angry when their knowledge and expectations don't match what they receive. A solution to support customers can go a long way here."]},{"cell_type":"markdown","metadata":{"id":"WELEGdS_fq32"},"source":["**Product Opportunity**\n","\n","By focusing on the products (specific shoes) within this topic, we can identify the top 5 shoes that seem to have fit (product) sizing issues. By using the below list, Nike can focus on specific products and make changes in their design to better address the sizing of the product in future iterations."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nodr_lvxcx-F"},"outputs":[],"source":["print('top 5 products to address:')\n","df_prod_count.head(5)"]},{"cell_type":"markdown","source":["# Conclusion\n","\n","In this notebook, we successfully performed topic modeling on Amazon reviews related to Nike products using Latent Dirichlet Allocation (LDA). The key steps included:\n","\n","Data Loading and Preprocessing:\n","\n","We efficiently loaded and preprocessed the text data by cleaning, tokenizing, removing stopwords, and lemmatizing the reviews. This helped to standardize the text and make it ready for topic modeling.\n","Topic Modeling with LDA:\n","\n","We used the LDA algorithm to discover hidden topics within the review data. The model was trained using a set number of topics, and key parameters like n_topics and max_iter were tuned to ensure better performance.\n","Model Evaluation:\n","\n","The model's performance was evaluated using log-likelihood and perplexity, providing insights into the coherence of topics generated by the LDA model.\n","Topic Visualization:\n","\n","We visualized the topics using both textual lists of top words and word clouds, allowing for a more intuitive understanding of the main themes present in the reviews.\n","Key Insights:\n","The topics generated by the LDA model give us a clearer picture of the main concerns and points of interest from customer reviews, ranging from product quality to customer satisfaction.\n","By tuning the LDA model and evaluating its performance, we ensured that the generated topics were coherent and relevant, providing valuable insights to the Nike brand regarding customer feedback.\n","This topic modeling approach can be extended to other product categories, allowing businesses to automatically uncover important themes in large-scale review data, thereby enabling better decision-making based on customer feedback."],"metadata":{"id":"nUhOnMo0LOX9"}},{"cell_type":"markdown","metadata":{"id":"Q3D69G2sErhN"},"source":["# 9.&nbsp; References"]},{"cell_type":"markdown","metadata":{"id":"EaRvn3OJezhS"},"source":["* [1] Latent Dirichlet allocation, Wikipedia, (https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation)\n","* [2] Text Preprocessing and Basic Text Mining, https://tmtoolkit.readthedocs.io/en/latest/preprocessing.html#Lemmatization-and-token-normalization)\n","* [3] TextBlob Tutorial: Quickstart, https://textblob.readthedocs.io/en/dev/quickstart.html#sentiment-analysis\n","\n"]}],"metadata":{"colab":{"collapsed_sections":["Q3D69G2sErhN"],"provenance":[{"file_id":"1Tr_aTiLr2FwUkMFagX_pJjsDqlqvEriJ","timestamp":1728828066098}],"toc_visible":true,"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}